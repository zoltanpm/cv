
@article{majdik2005,
	title = {Power without persuasion: {The} politics of direct presidential action [{Book} {Review}]},
	volume = {8},
	copyright = {All rights reserved},
	number = {3},
	journal = {Rhetoric \& Public Affairs},
	author = {Majdik, Zoltan P.},
	year = {2005},
	pages = {532--534},
}

@article{majdik2016a,
	title = {On rhetoric between science and society [lead review essay]},
	volume = {19},
	copyright = {All rights reserved},
	number = {1},
	journal = {Rhetoric \& Public Affairs},
	author = {Majdik, Zoltan P.},
	year = {2016},
	pages = {91--108},
}

@article{tillery_hyperrationality_2021,
	title = {Hyperrationality and {Rhetorical} {Constellations} in {Digital} {Climate} {Change} {Denial}: {A} {Multi}-{Methodological} {Analysis} of the {Discourse} of {Watts} up with {That}},
	volume = {0},
	issn = {1057-2252},
	shorttitle = {Hyperrationality and {Rhetorical} {Constellations} in {Digital} {Climate} {Change} {Denial}},
	url = {https://doi.org/10.1080/10572252.2021.2019317},
	doi = {10.1080/10572252.2021.2019317},
	abstract = {Using a multi-methodological approach, we analyze member comments in Watts Up With That (WUWT), a climate skeptical Facebook group. Quantitative topic modeling revealed that members claim hyperrationality to undermine climate science. Science-based terms were often connected to other topics, such as immigration and LGBTQ+ rights, creating rhetorical constellations that shifted rhetoric from technical spaces into political and ideological ones. These findings have implications for dealing with the challenge of misinformation’s circulation on social media.},
	number = {0},
	urldate = {2022-03-29},
	journal = {Technical Communication Quarterly},
	author = {Tillery, Denise and Bloomfield, Emma Frances},
	month = dec,
	year = {2021},
	note = {Publisher: Routledge
\_eprint: https://doi.org/10.1080/10572252.2021.2019317},
	keywords = {Hyperrationality, climate change skepticism, digital rhetoric, mixed methods, rhetorical constellations},
	pages = {1--18},
}

@article{majdik2022,
	title = {Building better machine learning models for rhetorical analyses: {The} use of rhetorical feature sets to train artificial neural network models},
	journal = {Technical Communication Quarterly},
	author = {Majdik, Zoltan P.},
	year = {2022},
}

@book{condit_meanings_1999,
	title = {The meanings of the gene: {Public} debates about human heredity},
	isbn = {978-0-299-16364-8},
	shorttitle = {The meanings of the gene},
	abstract = {The Meanings of the Gene is a compelling look at societal hopes and fears about genetics in the course of the twentieth century. The work of scientists and doctors in advancing genetic research and its applications has been accompanied by plenty of discussion in the popular press—from Good Housekeeping and Forbes to Ms. and the Congressional Record—about such topics as eugenics, sterilization, DNA, genetic counseling, and sex selection. By demonstrating the role of rhetoric and ideology in public discussions about genetics, Condit raises the controversial question, Who shapes decisions about genetic research and its consequences for humans—scientists, or the public? Analyzing hundreds of stories from American magazines—and, later, television news—from the 1910s to the 1990s, Condit identifies three central and enduring public worries about genetics: that genes are deterministic arbiters of human fate; that genetics research can be used for discriminatory ends; and that advances in genetics encourage perfectionistic thinking about our children. Other key public concerns that Condit highlights are the complexity of genetic decision-making and potential for invasion of privacy; conflict over the human genetic code and experimentation with DNA; and family genetics and reproductive decisions. Her analysis reveals a persistent debate in the popular media between themes of genetic determinism (such as eugenics) and more egalitarian views that place genes within the complexity of biological and social life. The Meanings of the Gene offers an insightful view of our continuing efforts to grapple with our biological natures and to define what it means, and will mean in the future, to be human.},
	language = {en},
	publisher = {Univ of Wisconsin Press},
	author = {Condit, Celeste Michelle},
	year = {1999},
	note = {Google-Books-ID: CgjzRXnRFQcC},
	keywords = {Social Science / Anthropology / General},
}

@book{ceccarelli2013,
	title = {On the frontier of science: {An} american rhetoric of exploration and exploitation},
	isbn = {978-0-87013-034-2},
	shorttitle = {On the frontier of science},
	abstract = {“The frontier of science” is a metaphor that has become ubiquitous in American rhetoric, from its first appearance in the public address of early twentieth-century American intellectuals and politicians who aligned a mythic national identity with scientific research, to its more recent use in scientists’ arguments in favor of increased research funding. Here, Leah Ceccarelli explores what is selected and what is deflected when this metaphor is deployed, its effects on those who use it, and what rhetorical moves are made by those who try to counter its appeal. In her research, Ceccarelli discovers that “the frontier of science” evokes a scientist who is typically male, a risk taker, an adventurous loner—someone separated from a public that both envies and distrusts him, with a manifest destiny to penetrate the unknown. It conjures a competitive desire to claim the riches of a new territory before others can do the same. Closely reading the public address of scientists and politicians and the reception of their audiences, this book shows how the frontier of science metaphor constrains American speakers, helping to guide the ends of scientific research in particular ways and sometimes blocking scientists from attaining the very goals they set out to achieve.},
	language = {en},
	publisher = {MSU Press},
	author = {Ceccarelli, Leah},
	year = {2013},
	note = {Google-Books-ID: mVOtAgAAQBAJ},
	keywords = {Language Arts \& Disciplines / General, Language Arts \& Disciplines / Rhetoric},
}

@article{walsh_visual_2015,
	title = {The visual rhetoric of climate change},
	volume = {6},
	number = {4},
	journal = {Wiley Interdisciplinary Reviews: Climate Change},
	author = {Walsh, Lynda},
	year = {2015},
	note = {Publisher: Wiley Online Library},
	pages = {361--368},
}

@incollection{cagle_tweeting_2017,
	title = {Tweeting the {Anthropocene}: \#400ppm as {Networked} {Event}},
	shorttitle = {Tweeting the {Anthropocene}},
	url = {https://uknowledge.uky.edu/wrd_facpub/10},
	booktitle = {Scientific {Communication}: {Practices}, {Theories}, and {Pedagogies}},
	author = {Cagle, Lauren and Tillery, Denise},
	editor = {Yu, Han and Northcut, Kathryn M.},
	year = {2017},
	pages = {131--148},
}

@article{kelley_using_2022,
	title = {Using language in social media posts to study the network dynamics of depression longitudinally},
	volume = {13},
	copyright = {2022 The Author(s)},
	issn = {2041-1723},
	url = {https://www.nature.com/articles/s41467-022-28513-3},
	doi = {10.1038/s41467-022-28513-3},
	abstract = {Network theory of mental illness posits that causal interactions between symptoms give rise to mental health disorders. Increasing evidence suggests that depression network connectivity may be a risk factor for transitioning and sustaining a depressive state. Here we analysed social media (Twitter) data from 946 participants who retrospectively self-reported the dates of any depressive episodes in the past 12 months and current depressive symptom severity. We construct personalised, within-subject, networks based on depression-related linguistic features. We show an association existed between current depression severity and 8 out of 9 text features examined. Individuals with greater depression severity had higher overall network connectivity between depression-relevant linguistic features than those with lesser severity. We observed within-subject changes in overall network connectivity associated with the dates of a self-reported depressive episode. The connectivity within personalized networks of depression-associated linguistic features may change dynamically with changes in current depression symptoms.},
	language = {en},
	number = {1},
	urldate = {2022-03-15},
	journal = {Nature Communications},
	author = {Kelley, Sean W. and Gillan, Claire M.},
	month = feb,
	year = {2022},
	note = {Number: 1
Publisher: Nature Publishing Group},
	keywords = {Computational models, Human behaviour},
	pages = {870},
}

@article{carley_dynamic_2012,
	title = {Dynamic network analysis ({DNA}) and {ORA}},
	abstract = {Dynamic network analysis can be used to assess complex socio-cultural systems from a network perspective. Key elements of this approach include: 1) dynamic meta-network representation of the who, what, where, how, why; representation of data from both a trail and network perspective where the nodes are attributed and the links probabilistic; extension of social networks analytics to the geo-spatial network analytics; techniques for assessing and forecasting change in networks; infrastructure tools to support data extraction, analysis and forecasting ranging from machine-learning models for network extraction to agent-based models for assessing the impact of the co-evolution of networks in various domains on human socio-cultural behavior.},
	author = {Carley, Kathleen and Pfeffer, Juergen and Nicholson, D.M.},
	month = jul,
	year = {2012},
	pages = {265--274},
}

@inproceedings{carley_near_2013,
	address = {New York, NY, USA},
	series = {{ASONAM} '13},
	title = {Near real time assessment of social media using geo-temporal network analytics},
	isbn = {978-1-4503-2240-9},
	url = {https://doi.org/10.1145/2492517.2492561},
	doi = {10.1145/2492517.2492561},
	abstract = {When a crisis occurs, there is often little time to evaluate the situation and determine how best to respond. We use rapid ethnographic methods centered on the construction of geo-temporally contextualized social and knowledge networks. By utilizing a combination of Twitter and news media, the consulate attack in Libya were examined in near real time. In this work we outline a procedure to extract key insights from the event as an event unfolds using a suite of tools developed by a team of researchers from two universities.},
	urldate = {2022-03-15},
	booktitle = {Proceedings of the 2013 {IEEE}/{ACM} {International} {Conference} on {Advances} in {Social} {Networks} {Analysis} and {Mining}},
	publisher = {Association for Computing Machinery},
	author = {Carley, Kathleen M. and Pfeffer, Jürgen and Liu, Huan and Morstatter, Fred and Goolsby, Rebecca},
	month = aug,
	year = {2013},
	pages = {517--524},
}

@article{grahametal2021,
	title = {A dashboard for exploring clinical trials sponsorship and potential virtual monopolies},
	volume = {4},
	number = {4},
	journal = {JAMIA open},
	author = {Graham, S. Scott and Majdik, Zoltan P. and Barbour, Joshua B. and Rousseau, Justin F.},
	year = {2021},
	note = {Publisher: Oxford University Press},
	pages = {ooab089},
}

@article{majdikplatt2012,
	title = {Selling {Certainty}: {Genetic} {Complexity} and {Moral} {Urgency} in {Myriad} {Genetics}' {BRAC} {Analysis} {Campaign}},
	volume = {42},
	copyright = {All rights reserved},
	shorttitle = {Selling {Certainty}},
	number = {2},
	journal = {Rhetoric Society Quarterly},
	author = {Majdik, Zoltan P. and Platt, Carrie Anne},
	year = {2012},
	note = {Publisher: Taylor \& Francis},
	pages = {120--143},
}

@article{majdiketal2011,
	title = {Calculating the {Weather}: {Deductive} {Reasoning} and {Disciplinary} {Telos} in {Cleveland} {Abbe}'s {Rhetorical} {Transformation} of {Meteorology}},
	volume = {97},
	copyright = {All rights reserved},
	shorttitle = {Calculating the {Weather}},
	number = {1},
	journal = {Quarterly Journal of Speech},
	author = {Majdik, Zoltan P. and Platt, Carrie Anne and Meister, Mark},
	year = {2011},
	note = {Publisher: Taylor \& Francis},
	pages = {74--99},
}

@article{plattmajdik2012,
	title = {The place of religion in {Habermas}'s transformed public sphere},
	volume = {49},
	copyright = {All rights reserved},
	number = {2},
	journal = {Argumentation and Advocacy},
	author = {Platt, Carrie Anne and Majdik, Zoltan P.},
	year = {2012},
	note = {Publisher: Taylor \& Francis},
	pages = {138--141},
}

@article{majdiketal2008,
	title = {The {Presidential} {Debates} of 2004: {Contested} {Moments} in the {Democratic} {Experiment}.},
	volume = {6},
	copyright = {All rights reserved},
	shorttitle = {The {Presidential} {Debates} of 2004},
	number = {1},
	journal = {Controversia},
	author = {Majdik, Zoltan P. and Kephart III, John M. and Goodnight, G. Thomas},
	year = {2008},
}

@incollection{majdik2014,
	address = {Thousand Oaks, CA},
	title = {Biological citizenship},
	copyright = {All rights reserved},
	booktitle = {Encyclopedia of {Health} {Communication}},
	publisher = {Sage},
	author = {Majdik, Zoltan P.},
	year = {2014},
	pages = {105--106},
}

@article{majdik2016,
	title = {Expertise as {Practice}: {A} {Response} to {DeVasto}},
	volume = {5},
	copyright = {All rights reserved},
	shorttitle = {Expertise as {Practice}},
	number = {11},
	journal = {Social Epistemology Review and Reply Collective},
	author = {Majdik, Zoltan},
	year = {2016},
	pages = {1--6},
}

@article{majdik2011,
	title = {On delimiting rhetorical invention in biopolitics: {A} rejoinder to {Lynch}},
	volume = {14},
	copyright = {All rights reserved},
	shorttitle = {On delimiting rhetorical invention in biopolitics},
	number = {2},
	journal = {Rhetoric \& Public Affairs},
	author = {Majdik, Zoltan P.},
	year = {2011},
	note = {Publisher: Michigan State University Press},
	pages = {379--389},
}

@article{majdik2009a,
	title = {Judging direct-to-consumer genetics: {Negotiating} expertise and agency in public biotechnological practice},
	volume = {12},
	copyright = {All rights reserved},
	shorttitle = {Judging direct-to-consumer genetics},
	number = {4},
	journal = {Rhetoric \& Public Affairs},
	author = {Majdik, Zoltan P.},
	year = {2009},
	note = {Publisher: Michigan State University Press},
	pages = {571--605},
}

@incollection{majdik2006,
	address = {Washington, DC},
	title = {Quo vadis, political debate? {Truth}-telling through comedy in {Jon} {Stewart}'s {Crossfire} appearance},
	copyright = {All rights reserved},
	booktitle = {Engaging argument: {Proceedings} of the {NCA}/{AFA} conference on argumentation},
	publisher = {National Communication Association},
	author = {Majdik, Zoltan P.},
	editor = {Riley, Patricia and Zarefsky, Marc},
	year = {2006},
	pages = {394--401},
}

@incollection{majdik2009,
	address = {Washington, DC},
	title = {Between morality and ethics: {Risk} and argument in direct-to-consumer genetics},
	copyright = {All rights reserved},
	booktitle = {Concerning argument: {Selected} papers from teh 15th {Biennial} {Conference} on {Argumentation}},
	publisher = {National Communication Association},
	author = {Majdik, Zoltan P.},
	editor = {Jacobs, Scott and Zarefsky, Marc},
	year = {2009},
	pages = {495--505},
}

@article{majdik2012,
	title = {Reply to {Derek} {Ross}’“{Ambiguous} {Weighting} and {Nonsensical} {Sense}”},
	copyright = {All rights reserved},
	journal = {Social Epistemology Review and Reply Collective},
	author = {Majdik, Zoltan},
	year = {2012},
	pages = {1--5},
}

@article{duchshereretal2020,
	title = {Immunized against science: {Narrative} community building among vaccine refusing/hesitant parents},
	volume = {29},
	copyright = {All rights reserved},
	issn = {0963-6625},
	shorttitle = {Immunized against science},
	url = {https://doi.org/10.1177/0963662520921537},
	doi = {10.1177/0963662520921537},
	abstract = {Recent outbreaks of measles have centered in specific communities, pointing to the influence of social ties on vaccination practices. This study adds to the conversation on public understanding of vaccine-related science, documenting how the individualist epistemologies highlighted in prior research are externalized and validated in communication with others, focusing on how the narrative strategies used to do so contribute to community building among vaccine refusing and hesitant parents. Through qualitative content analysis of testimonials given to the creators of the anti-vaccination documentary VaxXed, we identify how the common narrative strategies used to question the scientific consensus on vaccines—distrust of doctors, self-diagnosis, building credibility, advocacy, and community building—build a competing consensus based on personal expertise. With this approach, we are better able to understand how participation in online communities strengthens the privileging of individualist epistemologies among vaccine refusing and hesitant parents.},
	language = {en},
	number = {4},
	urldate = {2020-08-20},
	journal = {Public Understanding of Science},
	author = {Duchsherer, Amy and Jason, Mal and Platt, Carrie Anne and Majdik, Zoltan P},
	year = {2020},
	note = {Publisher: SAGE Publications Ltd},
	pages = {419--435},
}

@article{hassanetal2017,
	title = {{ClaimBuster}: the first-ever end-to-end fact-checking system},
	volume = {10},
	issn = {2150-8097},
	shorttitle = {{ClaimBuster}},
	url = {https://dl.acm.org/doi/10.14778/3137765.3137815},
	doi = {10.14778/3137765.3137815},
	abstract = {Our society is struggling with an unprecedented amount of falsehoods, hyperboles, and half-truths. Politicians and organizations repeatedly make the same false claims. Fake news floods the cyberspace and even allegedly influenced the 2016 election. In fighting false information, the number of active fact-checking organizations has grown from 44 in 2014 to 114 in early 2017.
              1
              Fact-checkers vet claims by investigating relevant data and documents and publish their verdicts. For instance, PolitiFact.com, one of the earliest and most popular fact-checking projects, gives factual claims truthfulness ratings such as True, Mostly True, Half true, Mostly False, False, and even "Pants on Fire". In the U.S., the election year made fact-checking a part of household terminology. For example, during the first presidential debate on September 26, 2016, NPR.org's live fact-checking website drew 7.4 million page views and delivered its biggest traffic day ever.},
	language = {en},
	number = {12},
	urldate = {2022-01-31},
	journal = {Proceedings of the VLDB Endowment},
	author = {Hassan, Naeemul and Zhang, Gensheng and Arslan, Fatma and Caraballo, Josue and Jimenez, Damian and Gawsane, Siddhant and Hasan, Shohedul and Joseph, Minumol and Kulkarni, Aaditya and Nayak, Anil Kumar and Sable, Vikas and Li, Chengkai and Tremayne, Mark},
	month = aug,
	year = {2017},
	pages = {1945--1948},
}

@article{lazarskietal2021,
	title = {Using {NLP} for {Fact} {Checking}: {A} {Survey}},
	volume = {5},
	shorttitle = {Using {NLP} for {Fact} {Checking}},
	doi = {10.3390/designs5030042},
	number = {3},
	journal = {Designs},
	author = {Lazarski, Eric and Al-Khassaweneh, Mahmood and Howard, Cynthia},
	year = {2021},
	note = {Publisher: Multidisciplinary Digital Publishing Institute},
	pages = {42},
}

@misc{googledeveloperssites2022,
	title = {Multiple changepoint detection and {Bayesian} model selection  {\textbar}  {TensorFlow} {Probability}},
	url = {https://www.tensorflow.org/probability/examples/Multiple_changepoint_detection_and_Bayesian_model_selection},
	author = {{Google Developers Sites}},
	year = {2022},
}

@incollection{jansen2002,
	address = {Lanham, MD},
	title = {Paris is always more than {Paris}},
	booktitle = {Critical communication theory: {Power}, media, gender, and technology},
	publisher = {Rowman \& Littlefield},
	author = {Jansen, Sue Curry},
	year = {2002},
	pages = {43--68},
}

@article{carrion_you_2018,
	title = {“{You} need to do your research”: {Vaccines}, contestable science, and maternal epistemology},
	volume = {27},
	shorttitle = {“{You} need to do your research”},
	number = {3},
	journal = {Public Understanding of Science},
	author = {Carrion, Melissa L.},
	year = {2018},
	note = {Publisher: SAGE Publications Sage UK: London, England},
	pages = {310--324},
}

@article{blythe_action_2008,
	title = {Action {Research} and {Wicked} {Environmental} {Problems}: {Exploring} {Appropriate} {Roles} for {Researchers} in {Professional} {Communication}},
	volume = {22},
	issn = {1050-6519},
	shorttitle = {Action {Research} and {Wicked} {Environmental} {Problems}},
	url = {https://doi.org/10.1177/1050651908315973},
	doi = {10.1177/1050651908315973},
	abstract = {The authors report on a 3-year action-research project designed to facilitate public involvement in the planned dredging of a canal and subsequent disposal of the dredged sediments. Their study reveals ways that community members struggle to define the problem and work together as they gather, share, and understand data relevant to that problem. The authors argue that the primary goal of action research related to environmental risk should be to identify and support the strategies used by community members rather than to educate the public. The authors maintain that this approach must be supported by a thorough investigation of basic rhetorical issues (audience, genre, stases, invention), and they illustrate how they used this approach in their study.},
	language = {en},
	number = {3},
	urldate = {2021-11-30},
	journal = {Journal of Business and Technical Communication},
	author = {Blythe, Stuart and Grabill, Jeffrey T. and Riley, Kirk},
	month = jul,
	year = {2008},
	note = {Publisher: SAGE Publications Inc},
	keywords = {action research, community-based research, environmental rhetoric, genre, invention, public, risk communication, stasis},
	pages = {272--298},
}

@article{druschke2017,
	title = {The {Radical} {Insufficiency} and {Wily} {Possibilities} of {RSTEM}},
	volume = {12},
	issn = {2151-2957},
	url = {https://pubs.lib.uiowa.edu/poroi/article/id/3392/},
	doi = {10.13008/2151-2957.1257},
	language = {None},
	number = {2},
	urldate = {2021-11-30},
	journal = {Poroi},
	author = {Druschke, Caroline Gottschalk},
	year = {2017},
}

@article{herndlcutlip2013,
	title = {"{How} {Can} {We} {Act}?" {A} {Praxiographical} {Program} for the {Rhetoric} of {Technology}, {Science}, and {Medicine}},
	volume = {9},
	shorttitle = {"{How} {Can} {We} {Act}?},
	doi = {10.13008/2151-2957.1163},
	abstract = {{\textless}p{\textgreater}The future of the rhetoric of science—which will increasingly take the form of a rhetoric of technology, science, and medicine (RTSM)—will be shaped by its move away from its modernist, humanistic roots in response to institutional pressures and historical contingencies. This paper advocates a “praxiographical” emphasis on the ability to intervene in science policy and other STEM-related discourses for the field of RTSM. It describes four research foci emerging from this emphasis to be used as areas of programmatic concern at an Institute for Applied Rhetoric of Science and Sustainability at the newly organized Patel College of Global Sustainability at the University of South Florida.{\textless}/p{\textgreater}},
	language = {None},
	number = {1},
	journal = {Poroi},
	author = {Herndl, Carl G. and Cutlip, Lauren Leigh},
	year = {2013},
}

@incollection{poursabzi-sangdehetal2021,
	address = {New York, NY, USA},
	title = {Manipulating and measuring model interpretability},
	isbn = {978-1-4503-8096-6},
	url = {https://doi.org/10.1145/3411764.3445315},
	abstract = {With machine learning models being increasingly used to aid decision making even in high-stakes domains, there has been a growing interest in developing interpretable models. Although many supposedly interpretable models have been proposed, there have been relatively few experimental studies investigating whether these models achieve their intended effects, such as making people more closely follow a model’s predictions when it is beneficial for them to do so or enabling them to detect when a model has made a mistake. We present a sequence of pre-registered experiments (N = 3, 800) in which we showed participants functionally identical models that varied only in two factors commonly thought to make machine learning models more or less interpretable: the number of features and the transparency of the model (i.e., whether the model internals are clear or black box). Predictably, participants who saw a clear model with few features could better simulate the model’s predictions. However, we did not find that participants more closely followed its predictions. Furthermore, showing participants a clear model meant that they were less able to detect and correct for the model’s sizable mistakes, seemingly due to information overload. These counterintuitive findings emphasize the importance of testing over intuition when developing interpretable models.},
	number = {237},
	booktitle = {Proceedings of the 2021 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Poursabzi-Sangdeh, Forough and Goldstein, Daniel G and Hofman, Jake M and Wortman Vaughan, Jennifer Wortman and Wallach, Hanna},
	year = {2021},
	keywords = {human-centered machine learning, interpretability, machine-assisted decision making},
	pages = {1--52},
}

@article{ribeiroetal2016,
	title = {"{Why} should {I} trust you?": {Explaining} the predictions of any classifier},
	shorttitle = {"{Why} should {I} trust you?},
	url = {http://arxiv.org/abs/1602.04938},
	abstract = {Despite widespread adoption, machine learning models remain mostly black boxes. Understanding the reasons behind predictions is, however, quite important in assessing trust, which is fundamental if one plans to take action based on a prediction, or when choosing whether to deploy a new model. Such understanding also provides insights into the model, which can be used to transform an untrustworthy model or prediction into a trustworthy one. In this work, we propose LIME, a novel explanation technique that explains the predictions of any classifier in an interpretable and faithful manner, by learning an interpretable model locally around the prediction. We also propose a method to explain models by presenting representative individual predictions and their explanations in a non-redundant way, framing the task as a submodular optimization problem. We demonstrate the flexibility of these methods by explaining different models for text (e.g. random forests) and image classification (e.g. neural networks). We show the utility of explanations via novel experiments, both simulated and with human subjects, on various scenarios that require trust: deciding if one should trust a prediction, choosing between models, improving an untrustworthy classifier, and identifying why a classifier should not be trusted.},
	journal = {arXiv:1602.04938 [cs, stat]},
	author = {Ribeiro, Marco Tulio and Singh, Sameer and Guestrin, Carlos},
	year = {2016},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{rudin2019,
	title = {Stop explaining black box machine learning models for high stakes decisions and use interpretable models instead},
	volume = {1},
	copyright = {2019 Springer Nature Limited},
	issn = {2522-5839},
	url = {https://www.nature.com/articles/s42256-019-0048-x},
	doi = {10.1038/s42256-019-0048-x},
	abstract = {Black box machine learning models are currently being used for high-stakes decision making throughout society, causing problems in healthcare, criminal justice and other domains. Some people hope that creating methods for explaining these black box models will alleviate some of the problems, but trying to explain black box models, rather than creating models that are interpretable in the first place, is likely to perpetuate bad practice and can potentially cause great harm to society. The way forward is to design models that are inherently interpretable. This Perspective clarifies the chasm between explaining black boxes and using inherently interpretable models, outlines several key reasons why explainable black boxes should be avoided in high-stakes decisions, identifies challenges to interpretable machine learning, and provides several example applications where interpretable models could potentially replace black box models in criminal justice, healthcare and computer vision.},
	language = {en},
	number = {5},
	journal = {Nature Machine Intelligence},
	author = {Rudin, Cynthia},
	year = {2019},
	keywords = {Computer science, Criminology, Science, Statistics, technology and society},
	pages = {206--215},
}

@article{grahamhopkins2021,
	title = {{AI} for social justice: {New} methodological horizons in technical communication},
	shorttitle = {{AI} for social justice},
	journal = {Technical Communication Quarterly},
	author = {Graham, S. Scott and Hopkins, Hannah R.},
	year = {2021},
	pages = {1--14},
}

@article{chen2021,
	title = {Interpretation of multi-label classification models using shapley values},
	url = {https://arxiv.org/abs/2104.10505v1},
	abstract = {Multi-label classification is a type of classification task, it is used when there are two or more classes, and the data point we want to predict may belong to none of the classes or all of them at the same time. In the real world, many applications are actually multi-label involved, including information retrieval, multimedia content annotation, web mining, and so on. A game theory-based framework known as SHapley Additive exPlanations (SHAP) has been applied to explain various supervised learning models without being aware of the exact model. Herein, this work further extends the explanation of multi-label classification task by using the SHAP methodology. The experiment demonstrates a comprehensive comparision of different algorithms on well known multi-label datasets and shows the usefulness of the interpretation.},
	language = {en},
	author = {Chen, Shikun},
	year = {2021},
}

@article{banerjeeetal2021,
	title = {Reading race: {AI} recognises patient's racial identity in medical images},
	shorttitle = {Reading race},
	url = {http://arxiv.org/abs/2107.10356},
	abstract = {Background: In medical imaging, prior studies have demonstrated disparate AI performance by race, yet there is no known correlation for race on medical imaging that would be obvious to the human expert interpreting the images. Methods: Using private and public datasets we evaluate: A) performance quantification of deep learning models to detect race from medical images, including the ability of these models to generalize to external environments and across multiple imaging modalities, B) assessment of possible confounding anatomic and phenotype population features, such as disease distribution and body habitus as predictors of race, and C) investigation into the underlying mechanism by which AI models can recognize race. Findings: Standard deep learning models can be trained to predict race from medical images with high performance across multiple imaging modalities. Our findings hold under external validation conditions, as well as when models are optimized to perform clinically motivated tasks. We demonstrate this detection is not due to trivial proxies or imaging-related surrogate covariates for race, such as underlying disease distribution. Finally, we show that performance persists over all anatomical regions and frequency spectrum of the images suggesting that mitigation efforts will be challenging and demand further study. Interpretation: We emphasize that model ability to predict self-reported race is itself not the issue of importance. However, our findings that AI can trivially predict self-reported race -- even from corrupted, cropped, and noised medical images -- in a setting where clinical experts cannot, creates an enormous risk for all model deployments in medical imaging: if an AI model secretly used its knowledge of self-reported race to misclassify all Black patients, radiologists would not be able to tell using the same data the model has access to.},
	journal = {arXiv:2107.10356 [cs, eess]},
	author = {Banerjee, Imon and Bhimireddy, Ananth Reddy and Burns, John L. and Celi, Leo Anthony and Chen, Li-Ching and Correa, Ramon and Dullerud, Natalie and Ghassemi, Marzyeh and Huang, Shih-Cheng and Kuo, Po-Chih and Lungren, Matthew P. and Palmer, Lyle and Price, Brandon J. and Purkayastha, Saptarshi and Pyrros, Ayis and Oakden-Rayner, Luke and Okechukwu, Chima and Seyyed-Kalantari, Laleh and Trivedi, Hari and Wang, Ryan and Zaiman, Zachary and Zhang, Haoran and Gichoya, Judy W.},
	year = {2021},
	keywords = {68-XX, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Computers and Society, Electrical Engineering and Systems Science - Image and Video Processing, I.2},
}

@article{visani_statistical_2020,
	title = {Statistical stability indices for {LIME}: obtaining reliable explanations for {Machine} {Learning} models},
	shorttitle = {Statistical stability indices for {LIME}},
	url = {http://arxiv.org/abs/2001.11757},
	abstract = {Nowadays we are witnessing a transformation of the business processes towards a more computation driven approach. The ever increasing usage of Machine Learning techniques is the clearest example of such trend. This sort of revolution is often providing advantages, such as an increase in prediction accuracy and a reduced time to obtain the results. However, these methods present a major drawback: it is very difficult to understand on what grounds the algorithm took the decision. To address this issue we consider the LIME method. We give a general background on LIME then, we focus on the stability issue: employing the method repeated times, under the same conditions, may yield to different explanations. Two complementary indices are proposed, to measure LIME stability. It is important for the practitioner to be aware of the issue, as well as to have a tool for spotting it. Stability guarantees LIME explanations to be reliable, therefore a stability assessment, made through the proposed indices, is crucial. As a case study, we apply both Machine Learning and classical statistical techniques to Credit Risk data. We test LIME on the Machine Learning algorithm and check its stability. Eventually, we examine the goodness of the explanations returned.},
	urldate = {2021-11-04},
	journal = {arXiv:2001.11757 [cs, stat]},
	author = {Visani, Giorgio and Bagli, Enrico and Chesani, Federico and Poluzzi, Alessandro and Capuzzo, Davide},
	month = nov,
	year = {2020},
	note = {arXiv: 2001.11757},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{wallisnerlich2005,
	title = {Disease metaphors in new epidemics: the {UK} media framing of the 2003 {SARS} epidemic},
	volume = {60},
	issn = {0277-9536},
	shorttitle = {Disease metaphors in new epidemics},
	url = {https://www.sciencedirect.com/science/article/pii/S0277953604005891},
	doi = {10.1016/j.socscimed.2004.11.031},
	abstract = {Since the emergence of HIV/AIDS in the 1980s, social scientists and sociologists of health and illness have been exploring the metaphorical framing of this infectious disease in its social context. Many have focused on the militaristic language used to report and explain this illness, a type of language that has permeated discourses of immunology, bacteriology and infection for at least a century. In this article, we examine how language and metaphor were used in the UK media's coverage of another previously unknown and severe infectious disease: Severe Acute Respiratory Syndrome (SARS). SARS offers an opportunity to explore the cultural framing of a less extraordinary epidemic disease. It therefore provides an analytical counter-weight to the very extensive body of interpretation that has developed around HIV/AIDS. By analysing the total reporting on SARS of five major national newspapers during the epidemic of spring 2003, we investigate how the reporting of SARS in the UK press was framed, and how this related to media, public and governmental responses to the disease. We found that, surprisingly, militaristic language was largely absent, as was the judgemental discourse of plague. Rather, the main conceptual metaphor used was SARS as a killer. SARS as a killer was a single unified entity, not an army or force. We provide some tentative explanations for this shift in linguistic framing by relating it to local political concerns, media cultures, and spatial factors.},
	language = {en},
	number = {11},
	urldate = {2021-09-10},
	journal = {Social Science \& Medicine},
	author = {Wallis, Patrick and Nerlich, Brigitte},
	month = jun,
	year = {2005},
	keywords = {AIDS, Epidemics, Metaphor, SARS, UK},
	pages = {2629--2639},
}

@article{macleod2021,
	title = {{COVID}-19 {Metaphors}},
	volume = {47},
	number = {S2},
	journal = {Critical Inquiry},
	author = {MacLeod, Norman},
	year = {2021},
	note = {Publisher: The University of Chicago Press Chicago, IL},
	pages = {S49--S51},
}

@misc{card_black_2017,
	title = {The “black box” metaphor in machine learning},
	url = {https://towardsdatascience.com/the-black-box-metaphor-in-machine-learning-4e57a3a1d2b0},
	abstract = {It has become quite common these days to hear people refer to modern machine learning systems as “black boxes”. As an example, consider a…},
	language = {en},
	urldate = {2021-05-20},
	journal = {Medium},
	author = {Card, Dallas},
	month = jul,
	year = {2017},
}

@article{hoyle_is_2021,
	title = {Is {Automated} {Topic} {Model} {Evaluation} {Broken}?: {The} {Incoherence} of {Coherence}},
	shorttitle = {Is {Automated} {Topic} {Model} {Evaluation} {Broken}?},
	url = {http://arxiv.org/abs/2107.02173},
	abstract = {Topic model evaluation, like evaluation of other unsupervised methods, can be contentious. However, the field has coalesced around automated estimates of topic coherence, which rely on the frequency of word co-occurrences in a reference corpus. Contemporary neural topic models surpass classical ones according to these metrics. At the same time, topic model evaluation suffers from a validation gap: automated coherence, developed for classical models, has not been validated using human experimentation for neural models. In addition, a meta-analysis of topic modeling literature reveals a substantial standardization gap in automated topic modeling benchmarks. To address the validation gap, we compare automated coherence with the two most widely accepted human judgment tasks: topic rating and word intrusion. To address the standardization gap, we systematically evaluate a dominant classical model and two state-of-the-art neural models on two commonly used datasets. Automated evaluations declare a winning model when corresponding human evaluations do not, calling into question the validity of fully automatic evaluations independent of human judgments.},
	language = {en},
	urldate = {2021-10-29},
	journal = {arXiv:2107.02173 [cs]},
	author = {Hoyle, Alexander and Goel, Pranav and Peskov, Denis and Hian-Cheong, Andrew and Boyd-Graber, Jordan and Resnik, Philip},
	month = oct,
	year = {2021},
	note = {arXiv: 2107.02173},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning},
}

@article{boyd_narrative_nodate,
	title = {The narrative arc: {Revealing} core narrative structures through text analysis},
	volume = {6},
	shorttitle = {The narrative arc},
	url = {https://www.science.org/doi/10.1126/sciadv.aba2196},
	doi = {10.1126/sciadv.aba2196},
	number = {32},
	urldate = {2021-10-27},
	journal = {Science Advances},
	author = {Boyd, Ryan L. and Blackburn, Kate G. and Pennebaker, James W.},
	note = {Publisher: American Association for the Advancement of Science},
	pages = {eaba2196},
}

@article{nguyen2021,
	title = {Transparency is surveillance},
	volume = {n/a},
	issn = {1933-1592},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/phpr.12823},
	doi = {10.1111/phpr.12823},
	abstract = {In her BBC Reith Lectures on Trust, Onora O’Neill offers a short, but biting, criticism of transparency. People think that trust and transparency go together but in reality, says O'Neill, they are deeply opposed. Transparency forces people to conceal their actual reasons for action and invent different ones for public consumption. Transparency forces deception. I work out the details of her argument and worsen her conclusion. I focus on public transparency – that is, transparency to the public over expert domains. I offer two versions of the criticism. First, the epistemic intrusion argument: The drive to transparency forces experts to explain their reasoning to non-experts. But expert reasons are, by their nature, often inaccessible to non-experts. So the demand for transparency can pressure experts to act only in those ways for which they can offer public justification. Second, the intimate reasons argument: In many cases of practical deliberation, the relevant reasons are intimate to a community and not easily explicable to those who lack a particular shared background. The demand for transparency, then, pressures community members to abandon the special understanding and sensitivity that arises from their particular experiences. Transparency, it turns out, is a form of surveillance. By forcing reasoning into the explicit and public sphere, transparency roots out corruption — but it also inhibits the full application of expert skill, sensitivity, and subtle shared understandings. The difficulty here arises from the basic fact that human knowledge vastly outstrips any individual’s capacities. We all depend on experts, which makes us vulnerable to their biases and corruption. But if we try to wholly secure our trust — if we leash groups of experts to pursuing only the goals and taking only the actions that can be justified to the non-expert public — then we will undermine their expertise. We need both trust and transparency, but they are in essential tension. This is a deep practical dilemma; it admits of no neat resolution, but only painful compromise.},
	language = {en},
	number = {n/a},
	urldate = {2021-10-21},
	journal = {Philosophy and Phenomenological Research},
	author = {Nguyen, C. Thi},
	year = {2021},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/phpr.12823},
}

@book{johnsonetal2017,
	title = {Program facilities and sustainable computing infrastructures: an on-the-ground case},
	isbn = {978-1-315-53817-4},
	shorttitle = {Program facilities and sustainable computing infrastructures},
	abstract = {Chapter 5 addresses how sustainable computing infrastructures can intersect with the push to make technical communication programs lean. This on-the-ground case considers how technical communication programs might outfit their program facilities without eschewing the responsibility to provide affordable essentials for local students or the global responsibility to mitigate their environmental effects. To anchor this discussion of how lean products and methodologies can operate in material spaces, Chapter 5 presents the case of a computer classroom redesign and explores how different software, hardware, and material configurations support technical communication program work.},
	publisher = {Routledge},
	author = {Johnson, Meredith A. and Simmons, W. Michele and Sullivan, Patricia},
	year = {2017},
}

@article{jones2016,
	title = {The technical communicator as advocate: {Integrating} a social justice approach in technical communication},
	volume = {46},
	issn = {0047-2816},
	shorttitle = {The technical communicator as advocate},
	url = {https://doi.org/10.1177/0047281616639472},
	doi = {10.1177/0047281616639472},
	abstract = {This article argues for the need for a social justice approach to technical communication research and pedagogy. Given previous calls by scholars in technical and professional communication (TPC) for an attention to diversity, inclusion, and equality, the author examines the place and purpose of social justice in TPC and provides useful approaches for promoting a more genuine and critical interrogation of how work in TPC impacts the human experience.},
	language = {en},
	number = {3},
	urldate = {2021-10-15},
	journal = {Journal of Technical Writing and Communication},
	author = {Jones, Natasha N.},
	month = jul,
	year = {2016},
	note = {Publisher: SAGE Publications Inc},
	keywords = {diversity, inclusion, social justice, technical and professional communication},
	pages = {342--361},
}

@article{laueretal2018,
	title = {Hand collecting and coding versus data-driven methods in technical and professional communication research},
	volume = {61},
	issn = {1558-1500},
	doi = {10.1109/TPC.2018.2870632},
	abstract = {Background: Qualitative technical communication research often produces datasets that are too large to manage effectively with hand-coded approaches. Text-mining methods, used carefully, may uncover patterns and provide results for larger datasets that are more easily reproduced and scaled. Research questions: 1. To what degree can hand collection results be replicated by automated data collection? 2. To what degree can hand-coded results be replicated by machine coding? 3. What are the affordances and limitations of each method? Literature review:We introduce the stages of data collection and analysis that researchers typically discuss in the literature, and show how researchers in technical communication and other fields have discussed the affordances and limitations of hand collection and coding versus automated methods throughout each stage. Research methodology: We utilize an existing dataset that was hand-collected and hand-coded. We discuss the collection and coding processes, and demonstrate how they might be replicated with web scraping and machine coding. Results/discussion: We found that web scraping demonstrated an obvious advantage of automated data collection: speed. Machine coding was able to provide comparable outputs to hand coding for certain types of data; for more nuanced and verbally complex data, machine coding was less useful and less reliable. Conclusions: Our findings highlight the importance of considering the context of a particular project when weighing the affordances and limitations of hand collecting and coding over automated approaches. Ultimately, a mixed-methods approach that relies on a combination of hand coding and automated coding should prove to be the most productive for current and future kinds of technical communication work, in which close attention to the nuances of language is critical, but in which processing large amounts of data would yield significant benefits as well.},
	number = {4},
	journal = {IEEE Transactions on Professional Communication},
	author = {Lauer, Claire and Brumberger, Eva and Beveridge, Aaron},
	year = {2018},
	note = {Conference Name: IEEE Transactions on Professional Communication},
	keywords = {Coding, Data collection, Encoding, Machine learning, Natural language processing, Text mining, data analysis, machine reading, natural language processing (NLP), text mining, web scraping},
	pages = {389--408},
}

@article{graham2009,
	title = {Agency and the {Rhetoric} of {Medicine}: {Biomedical} {Brain} {Scans} and the {Ontology} of {Fibromyalgia}},
	volume = {18},
	issn = {1057-2252},
	shorttitle = {Agency and the {Rhetoric} of {Medicine}},
	url = {https://doi.org/10.1080/10572250903149555},
	doi = {10.1080/10572250903149555},
	abstract = {Recent agency scholarship has provided compelling accounts of how individuals can strategically occupy authoritative positions, in order to instantiate change. This article explores the discursive mechanisms of this type of agency in the legitimization of disease. Drawing on ethnographic research, this article investigates how a non-human agent (brain scans) contributed to fibromyalgia's acceptance within the highly regulated discourses of western biomedicine.},
	number = {4},
	urldate = {2021-04-05},
	journal = {Technical Communication Quarterly},
	author = {Graham, S. Scott},
	month = sep,
	year = {2009},
	note = {Publisher: Routledge
\_eprint: https://doi.org/10.1080/10572250903149555},
	pages = {376--404},
}

@incollection{wynn2022,
	address = {London},
	title = {Exploring expert appeals to ethos with statistical corpus analysis: {Personal} and contextual factors and their influence on climate scientists' use of appeals to expertise},
	booktitle = {The {Routledge} {Handbook} on {Language} and {Persuasion}},
	publisher = {Routledge},
	author = {Wynn, James},
	editor = {Fahnestock, Jeanne and Harris, Randy Allen},
	year = {2022},
}

@article{sweeneyetal2013,
	title = {Hearing the voices of service user researchers in collaborative qualitative data analysis: the case for multiple coding},
	volume = {16},
	issn = {1369-6513, 1369-7625},
	shorttitle = {Hearing the voices of service user researchers in collaborative qualitative data analysis},
	url = {https://onlinelibrary.wiley.com/doi/10.1111/j.1369-7625.2012.00810.x},
	doi = {10.1111/j.1369-7625.2012.00810.x},
	abstract = {Background Health research is frequently conducted in multi-disciplinary teams, with these teams increasingly including service user researchers. Whilst it is common for service user researchers to be involved in data collection – most typically interviewing other service users – it is less common for service user researchers to be involved in data analysis and interpretation. This means that a unique and signiﬁcant perspective on the data is absent. Aim This study aims to use an empirical report of a study on Cognitive Behavioural Therapy for psychosis (CBTp) to demonstrate the value of multiple coding in enabling service users voices to be heard in team-based qualitative data analysis. Design The CBTp study employed multiple coding to analyse service users’ discussions of CBT for psychosis (CBTp) from the perspectives of a service user researcher, clinical researcher and psychology assistant. Multiple coding was selected to enable multiple perspectives to analyse and interpret data, to understand and explore diﬀerences and to build multi-disciplinary consensus.
Results Multiple coding enabled the team to understand where our views were commensurate and incommensurate and to discuss and debate diﬀerences. Through the process of multiple coding, we were able to build strong consensus about the data from multiple perspectives, including that of the service user researcher. Discussion Multiple coding is an important method for understanding and exploring multiple perspectives on data and building team consensus. This can be contrasted with inter-rater reliability which is only appropriate in limited circumstances.
Conclusion We conclude that multiple coding is an appropriate and important means of hearing service users’ voices in qualitative data analysis.},
	language = {en},
	number = {4},
	urldate = {2021-10-08},
	journal = {Health Expectations},
	author = {Sweeney, Angela and Greenwood, Kathryn E and Williams, Sally and Wykes, Til and Rose, Diana S},
	year = {2013},
	pages = {e89--e99},
}

@article{richardshemphill2018,
	title = {A practical guide to collaborative qualitative data analysis},
	volume = {37},
	number = {2},
	journal = {Journal of Teaching in Physical Education},
	author = {Richards, K. Andrew R. and Hemphill, Michael A.},
	year = {2018},
	pages = {225--231},
}

@article{strubelletal2019,
	title = {Energy and {Policy} {Considerations} for {Deep} {Learning} in {NLP}},
	url = {http://arxiv.org/abs/1906.02243},
	abstract = {Recent progress in hardware and methodology for training neural networks has ushered in a new generation of large networks trained on abundant data. These models have obtained notable gains in accuracy across many NLP tasks. However, these accuracy improvements depend on the availability of exceptionally large computational resources that necessitate similarly substantial energy consumption. As a result these models are costly to train and develop, both financially, due to the cost of hardware and electricity or cloud compute time, and environmentally, due to the carbon footprint required to fuel modern tensor processing hardware. In this paper we bring this issue to the attention of NLP researchers by quantifying the approximate financial and environmental costs of training a variety of recently successful neural network models for NLP. Based on these findings, we propose actionable recommendations to reduce costs and improve equity in NLP research and practice.},
	urldate = {2021-10-06},
	journal = {arXiv:1906.02243 [cs]},
	author = {Strubell, Emma and Ganesh, Ananya and McCallum, Andrew},
	month = jun,
	year = {2019},
	note = {arXiv: 1906.02243},
	keywords = {Computer Science - Computation and Language},
}

@book{noble2018,
	title = {Algorithms of oppression: {How} search engines reinforce racism},
	isbn = {978-1-4798-6676-2},
	shorttitle = {Algorithms of oppression},
	abstract = {A revealing look at how negative biases against women of color are embedded in search engine results and algorithms Run a Google search for “black girls”—what will you find? “Big Booty” and other sexually explicit terms are likely to come up as top search terms. But, if you type in “white girls,” the results are radically different. The suggested porn sites and un-moderated discussions about “why black women are so sassy” or “why black women are so angry” presents a disturbing portrait of black womanhood in modern society.In Algorithms of Oppression, Safiya Umoja Noble challenges the idea that search engines like Google offer an equal playing field for all forms of ideas, identities, and activities. Data discrimination is a real social problem; Noble argues that the combination of private interests in promoting certain sites, along with the monopoly status of a relatively small number of Internet search engines, leads to a biased set of search algorithms that privilege whiteness and discriminate against people of color, specifically women of color.Through an analysis of textual and media searches as well as extensive research on paid online advertising, Noble exposes a culture of racism and sexism in the way discoverability is created online. As search engines and their related companies grow in importance—operating as a source for email, a major vehicle for primary and secondary school learning, and beyond—understanding and reversing these disquieting trends and discriminatory practices is of utmost importance.An original, surprising and, at times, disturbing account of bias on the internet, Algorithms of Oppression contributes to our understanding of how racism is created, maintained, and disseminated in the 21st century.},
	language = {en},
	publisher = {NYU Press},
	author = {Noble, Safiya Umoja},
	year = {2018},
	keywords = {Computers / Social Aspects, Computers / Web / Search Engines, Social Science / Discrimination \& Race Relations},
}

@article{leeetal2020,
	title = {{BioBERT}: a pre-trained biomedical language representation model for biomedical text mining},
	volume = {36},
	issn = {1367-4803},
	shorttitle = {{BioBERT}},
	url = {https://doi.org/10.1093/bioinformatics/btz682},
	doi = {10.1093/bioinformatics/btz682},
	abstract = {Biomedical text mining is becoming increasingly important as the number of biomedical documents rapidly grows. With the progress in natural language processing (NLP), extracting valuable information from biomedical literature has gained popularity among researchers, and deep learning has boosted the development of effective biomedical text mining models. However, directly applying the advancements in NLP to biomedical text mining often yields unsatisfactory results due to a word distribution shift from general domain corpora to biomedical corpora. In this article, we investigate how the recently introduced pre-trained language model BERT can be adapted for biomedical corpora.We introduce BioBERT (Bidirectional Encoder Representations from Transformers for Biomedical Text Mining), which is a domain-specific language representation model pre-trained on large-scale biomedical corpora. With almost the same architecture across tasks, BioBERT largely outperforms BERT and previous state-of-the-art models in a variety of biomedical text mining tasks when pre-trained on biomedical corpora. While BERT obtains performance comparable to that of previous state-of-the-art models, BioBERT significantly outperforms them on the following three representative biomedical text mining tasks: biomedical named entity recognition (0.62\% F1 score improvement), biomedical relation extraction (2.80\% F1 score improvement) and biomedical question answering (12.24\% MRR improvement). Our analysis results show that pre-training BERT on biomedical corpora helps it to understand complex biomedical texts.We make the pre-trained weights of BioBERT freely available at https://github.com/naver/biobert-pretrained, and the source code for fine-tuning BioBERT available at https://github.com/dmis-lab/biobert.},
	number = {4},
	journal = {Bioinformatics},
	author = {Lee, Jinhyuk and Yoon, Wonjin and Kim, Sungdong and Kim, Donghyeon and Kim, Sunkyu and So, Chan Ho and Kang, Jaewoo},
	year = {2020},
	pages = {1234--1240},
}

@misc{brownlee2020,
	title = {Why {Do} {I} {Get} {Different} {Results} {Each} {Time} in {Machine} {Learning}?},
	url = {https://machinelearningmastery.com/different-results-each-time-in-machine-learning/},
	abstract = {Are you getting different results for your machine learning algorithm? Perhaps your results differ from a tutorial and you want […]},
	language = {en-US},
	urldate = {2021-09-20},
	journal = {Machine Learning Mastery},
	author = {Brownlee, Jason},
	month = aug,
	year = {2020},
}

@article{angeli_metaphors_2012,
	title = {Metaphors in the {Rhetoric} of {Pandemic} {Flu}: {Electronic} {Media} {Coverage} of {H1N1} and {Swine} {Flu}},
	volume = {42},
	issn = {0047-2816},
	shorttitle = {Metaphors in the {Rhetoric} of {Pandemic} {Flu}},
	url = {https://doi.org/10.2190/TW.42.3.b},
	doi = {10.2190/TW.42.3.b},
	abstract = {Drawing on pandemic flu metaphor research and building on previous metaphor theory, this article uses rhetorical analysis to examine and move toward understanding the metaphors surrounding H1N1 and swine flu. To understand these metaphors, I created two Google Alerts for the terms “H1N1” and “swine flu” and collected data using these Google Alerts from November 10, 2009 to December 10, 2009. I then examined the headlines and content found in the news articles, blogs, and websites from the Google Alerts, and grouped the metaphors used in these headlines and content thematically. These themes work toward providing a rhetoric of pandemic flu, a rhetoric that might assist health care recipients in being more aware of how metaphors used in electronic media create meaning for health concerns.},
	language = {en},
	number = {3},
	urldate = {2021-09-13},
	journal = {Journal of Technical Writing and Communication},
	author = {Angeli, Elizabeth L.},
	month = jul,
	year = {2012},
	note = {Publisher: SAGE Publications Inc},
	pages = {203--222},
}

@book{burke_philosophy_1974,
	title = {The {Philosophy} of {Literary} {Form}},
	isbn = {978-0-520-02483-0},
	abstract = {From the ForewordThese pieces are selections from work done in the Thirties, a decade so changeable that I at first thought of assembling them under the title, "While Everything Flows."  Their primary interest is in speculation on the nature of linguistic, or symbolic, or literary action--and in a search for more precise ways of locating or defining such action. Words are aspects of a much wider communicative context, most of which is not verbal at all. Yet words also have a nature peculiarly their own. And when discussing them as modes of action, we must consider both this nature as words in themselves and the nature they get from the non-verbal scenes that support their acts. I shall be happy if the reader can say of this book that, while always considering words as acts upon a scene, it avoids the excess of environmentalist schools which are usually so eager to trace the relationships between act and scene that they neglect to trace the structure of the act itself.},
	language = {en},
	publisher = {University of California Press},
	author = {Burke, Kenneth},
	month = aug,
	year = {1974},
	keywords = {Literary Criticism / Semiotics \& Theory},
}

@book{lakoffjohnson1980,
	title = {Metaphors {We} {Live} {By}},
	isbn = {978-0-226-46800-6},
	abstract = {The now-classic Metaphors We Live By changed our understanding of metaphor and its role in language and the mind. Metaphor, the authors explain, is a fundamental mechanism of mind, one that allows us to use what we know about our physical and social experience to provide understanding of countless other subjects. Because such metaphors structure our most basic understandings of our experience, they are "metaphors we live by"—metaphors that can shape our perceptions and actions without our ever noticing them.  In this updated edition of Lakoff and Johnson's influential book, the authors supply an afterword surveying how their theory of metaphor has developed within the cognitive sciences to become central to the contemporary understanding of how we think and how we express our thoughts in language.},
	language = {en},
	publisher = {University of Chicago Press},
	author = {Lakoff, George and Johnson, Mark},
	month = nov,
	year = {1980},
	note = {Google-Books-ID: \_gc\_xQEACAAJ},
	keywords = {Language Arts \& Disciplines / General, Language Arts \& Disciplines / Linguistics / General, Philosophy / Mind \& Body, Science / Cognitive Science},
}

@article{levonian_bridging_nodate,
	title = {Bridging {Qualitative} and {Quantitative} {Methods} for {User} {Modeling}: {Tracing} {Cancer} {Patient} {Behavior} in an {Online} {Health} {Community}},
	abstract = {Researchers construct models of social media users to understand human behavior and deliver improved digital services. Such models use conceptual categories arranged in a taxonomy to classify unstructured user text data. In many contexts, useful taxonomies can be deﬁned via the incorporation of qualitative ﬁndings, a mixed-methods approach that offers the ability to create qualitatively-informed user models. But operationalizing taxonomies from the themes described in qualitative work is non-trivial and has received little explicit focus. We propose a process and explore challenges bridging qualitative themes to user models, for both operationalization of themes to taxonomies and the use of these taxonomies in constructing classiﬁcation models. For classiﬁcation of new data, we compare common keyword-based approaches to machine learning models. We demonstrate our process through an example in the health domain, constructing two user models tracing cancer patient experience over time in an online health community. We identify patterns in the model outputs for describing the longitudinal experience of cancer patients and reﬂect on the use of this process in future research.},
	language = {en},
	author = {Levonian, Zachary and Erikson, Drew Richard and Luo, Wenqi and Narayanan, Saumik and Rubya, Sabirat and Vachher, Prateek and Terveen, Loren and Yarosh, Svetlana},
	pages = {12},
}

@article{long_chance_2021,
	title = {Chance {Encounters}: {World} {Literature} {Between} the {Unexpected} and the {Probable}},
	shorttitle = {Chance {Encounters}},
	url = {https://culturalanalytics.org/article/25525-chance-encounters-world-literature-between-the-unexpected-and-the-probable},
	doi = {10.22148/001c.25525},
	abstract = {This essay brings probabilistic reasoning into concerted dialogue with book-historical and sociological approaches to world literature. Using extensive bibliographic data about literary translations into Japanese during the modern era, it develops a series of case studies at interrelated scales—the literary anthology, world library collections, and individual readers—to reason about the likelihood of certain authors or works being plucked from the swirling currents of the global traffic in books. At each scale, I consider how such data might inform the interpretations we give to the choice of one author over another in a given context. Woven into these case studies is an extended reflection on the history of probabilistic reasoning from the late-eighteenth century to the late-twentieth. What, this essay ultimately asks, might literary historians gain from taking this history seriously in our own appeals to chance as a form of historical explanation?},
	language = {en},
	urldate = {2021-08-04},
	journal = {Journal of Cultural Analytics},
	author = {Long, Hoyt},
	month = jul,
	year = {2021},
	note = {Publisher: Department of Languages, Literatures, and Cultures},
	pages = {25525},
}

@article{simon_autopsy_2021,
	title = {Autopsy of a metaphor: {The} origins, use and blind spots of the ‘infodemic’},
	issn = {1461-4448},
	shorttitle = {Autopsy of a metaphor},
	url = {https://doi.org/10.1177/14614448211031908},
	doi = {10.1177/14614448211031908},
	abstract = {In 2020, the term ‘infodemic’ rose from relative obscurity to becoming a popular catch-all metaphor, representing the perils of fast, wide-spreading (false) information about the coronavirus pandemic. It featured in thousands of academic publications and received widespread attention from policymakers and the media. In this article, we trace the origins and use of the ‘infodemic’ metaphor and examine the blind spots inherent in this seemingly intuitive term. Drawing from literature in the cognitive sciences and communication studies, we show why information does not spread like a virus and point out how the ‘infodemic’ metaphor can be misleading, as it conflates multiple forms of social behaviour, oversimplifies a complex situation and helps constitute a phenomenon for which concrete evidence remains patchy. We point out the existing tension between the usefulness of the widespread use of the term ‘infodemic’ and its uncritical adoption, which we argue can do more harm than good, potentially diluting the quality of academic work, public discourse and contributing to state overreach in policymaking.},
	language = {en},
	urldate = {2021-07-22},
	journal = {New Media \& Society},
	author = {Simon, Felix M and Camargo, Chico Q},
	month = jul,
	year = {2021},
	note = {Publisher: SAGE Publications},
	keywords = {COVID-19, WHO, digital media, infodemic, journalism, metaphor, misinformation, news, pandemic, policymaking, science},
	pages = {14614448211031908},
}

@article{bod2013,
	title = {Who's afraid of patterns?: {The} particular versus the universal and the meaning of humanities 3.0},
	volume = {128},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	shorttitle = {Who's afraid of patterns?},
	abstract = {The advent of Digital Humanities has enabled scholars to identify previously unknown patterns in the arts and letters; but the notion of pattern has also been subject to debate. In my response to the authors of this Forum, I argue that ‘pattern’ should not be confused with universal pattern. The term pattern itself is neutral with respect to being either particular or universal. Yet the testing and discovery of patterns – be they local or global – is greatly aided by digital tools. While such tools have been beneficial for the humanities, numerous scholars lack a sufficient grasp of the underlying assumptions and methods of these tools. I argue that in order to criticise and interpret the results of digital humanities properly, scholars must acquire a good working knowledge of the underlying tools and methods. Only then can digital humanities be fully integrated (humanities 3.0) with time-honoured (humanities 1.0) tools of hermeneutics and criticism.},
	language = {en},
	number = {4},
	urldate = {2020-07-23},
	journal = {Low Countries Historical Review},
	author = {Bod, Rens},
	year = {2013},
	pages = {171--180},
}

@misc{wynn2020,
	title = {E-thos project: {Climate} change},
	author = {Wynn, James},
	year = {2020},
	note = {https://doi.org/10.1184/R1/12964481.v1},
}

@article{devlinetal2019,
	title = {{BERT}: {Pre}-training of deep bidirectional transformers for language understanding},
	shorttitle = {Bert},
	url = {http://arxiv.org/abs/1810.04805},
	abstract = {We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models, BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5\% (7.7\% point absolute improvement), MultiNLI accuracy to 86.7\% (4.6\% absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).},
	journal = {arXiv:1810.04805 [cs]},
	author = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
	year = {2019},
	keywords = {Computer Science - Computation and Language},
}

@inproceedings{penningtonetal2014,
	address = {Doha, Qatar},
	title = {{GloVe}: {Global} vectors for word representation},
	shorttitle = {Glove},
	url = {http://aclweb.org/anthology/D14-1162},
	doi = {10.3115/v1/D14-1162},
	abstract = {Recent methods for learning vector space representations of words have succeeded in capturing ﬁne-grained semantic and syntactic regularities using vector arithmetic, but the origin of these regularities has remained opaque. We analyze and make explicit the model properties needed for such regularities to emerge in word vectors. The result is a new global logbilinear regression model that combines the advantages of the two major model families in the literature: global matrix factorization and local context window methods. Our model efﬁciently leverages statistical information by training only on the nonzero elements in a word-word cooccurrence matrix, rather than on the entire sparse matrix or on individual context windows in a large corpus. The model produces a vector space with meaningful substructure, as evidenced by its performance of 75\% on a recent word analogy task. It also outperforms related models on similarity tasks and named entity recognition.},
	language = {en},
	urldate = {2021-05-12},
	booktitle = {Proceedings of the 2014 {Conference} on {Empirical} {Methods} in {Natural} {Language} {Processing} ({EMNLP})},
	publisher = {Association for Computational Linguistics},
	author = {Pennington, Jeffrey and Socher, Richard and Manning, Christopher},
	year = {2014},
	pages = {1532--1543},
}

@book{rickert2013,
	title = {Ambient rhetoric: {The} attunements of rhetorical being},
	isbn = {978-0-8229-7869-5},
	shorttitle = {Ambient rhetoric},
	abstract = {In Ambient Rhetoric, Thomas Rickert seeks to dissolve the boundaries of the rhetorical tradition and its basic dichotomy of subject and object. With the advent of new technologies, new media, and the dispersion of human agency through external information sources, rhetoric can no longer remain tied to the autonomy of human will and cognition as the sole determinants in the discursive act.  Rickert develops the concept of ambience in order to engage all of the elements that comprise the ecologies in which we exist. Culling from Martin Heidegger’s hermeneutical phenomenology in Being and Time, Rickert finds the basis for ambience in Heidegger’s assertion that humans do not exist in a vacuum; there is a constant and fluid relation to the material, informational, and emotional spaces in which they dwell. Hence, humans are not the exclusive actors in the rhetorical equation; agency can be found in innumerable things, objects, and spaces. As Rickert asserts, it is only after we become attuned to these influences that rhetoric can make a first step toward sufficiency.  Rickert also recalls the foundational Greek philosophical concepts of kairos (time), chora (space/place), and periechon (surroundings) and cites their repurposing by modern and postmodern thinkers as “informational scaffolding” for how we reason, feel, and act. He discusses contemporary theory in cognitive science, rhetoric, and object-oriented philosophy to expand his argument for the essentiality of ambience to the field of rhetoric. Rickert then examines works of ambient music that incorporate natural and artificial sound, spaces, and technologies, finding them to be exemplary of a more fully resonant and experiential media.  In his preface, Rickert compares ambience to the fermenting of wine—how its distinctive flavor can be traced to innumerable factors, including sun, soil, water, region, and grape variety. The environment and company with whom it’s consumed further enhance the taste experience. And so it should be with rhetoric—to be considered among all of its influences. As Rickert demonstrates, the larger world that we inhabit (and that inhabits us) must be fully embraced if we are to advance as beings and rhetors within it.},
	language = {en},
	publisher = {University of Pittsburgh Press},
	author = {Rickert, Thomas},
	year = {2013},
	keywords = {Language Arts \& Disciplines / General, Language Arts \& Disciplines / Rhetoric},
}

@misc{vig2019,
	title = {Deconstructing {BERT}, part 2: {Visualizing} the inner workings of attention},
	shorttitle = {Deconstructing {BERT}, part 2},
	url = {https://towardsdatascience.com/deconstructing-bert-part-2-visualizing-the-inner-workings-of-attention-60a16d86b5c1},
	abstract = {A new visualization tool shows how BERT forms its distinctive attention patterns.},
	language = {en},
	journal = {Medium},
	author = {Vig, Jesse},
	year = {2019},
}

@article{zhuetal2021,
	title = {A machine learning algorithm for sorting online comments via topic modeling},
	abstract = {This article uses a machine learning algorithm to demonstrate a proof-of-concept case for moderating and managing online comments as a form of content moderation, which is an emerging area of interest for technical and professional communication (TPC) researchers. The algorithm sorts comments by topical similarity to a reference comment/article rather than display comments by linear time and popularity. This approach has the practical benefit of enabling TPC researchers to reconceptualize content display systems in dynamic ways.},
	language = {en},
	journal = {Communication Design Quarterly},
	author = {Zhu, Junzhe and Wickes, Elizabeth and Gallagher, John R},
	year = {2021},
	pages = {12},
}

@book{graham2020a,
	title = {Where's the rhetoric?: {Imagining} a unified field},
	isbn = {978-0-8142-5771-5},
	shorttitle = {Where's the rhetoric?},
	abstract = {The emergence of rhetorical new materialisms and computational rhetorics has provoked something of an existential crisis within rhetorical studies. In Where's the Rhetoric?, S. Scott Graham tackles this titular question by arguing first that scholarly efforts in rhetorical new materialisms and computational rhetoric be understood as coextensive with longstanding disciplinary commitments in rhetoric. In making this argument, Graham excavates the shared intellectual history of traditional rhetorical inquiry, rhetorical new materialisms, and computational rhetoric with particular emphasis on the works of Carolyn Miller, Kenneth Burke, and Henri Bergson.  Building on this foundation, Graham then argues for a more unified approach to contemporary rhetorical inquiry--one that eschews disciplinary demarcations between rhetoric's various subareas. Specifically, Graham uses his unified field theory to explore 1) the rise of the "tweetorial" as a parascientific genre, 2) inventional practices in new media design, 3) statistical approaches to understanding biomedical discourse, and 4) American electioneering rhetorics. The book overall demonstrates how seemingly disparate intellectual approaches within rhetoric can be made to speak productively to one another in the pursuit of shared scholarly goals around questions of genre, media, and political discourse--thereby providing a foundation for imagining a more unified field.},
	language = {en},
	publisher = {Ohio State University Press},
	author = {Graham, S. Scott},
	year = {2020},
	keywords = {Language Arts \& Disciplines / Communication Studies, Language Arts \& Disciplines / Rhetoric, Social Science / Media Studies},
}

@book{shaviro2003,
	title = {Connected, or, what it means to live in the network society},
	isbn = {978-0-8166-4363-9},
	abstract = {In the twenty-first century, a network society is emerging. Fragmented, visually saturated, characterized by rapid technological change and constant social upheavals, it is dizzying, excessive, and sometimes surreal. In this breathtaking work, Steven Shaviro investigates popular culture, new technologies, political change, and community disruption and concludes that science fiction and social reality have become virtually indistinguishable. Connected is made up of a series of mini-essays-on cyberpunk, hip-hop, film noir, Web surfing, greed, electronic surveillance, pervasive multimedia, psychedelic drugs, artificial intelligence, evolutionary psychology, and the architecture of Frank Gehry, among other topics. Shaviro argues that our strange new world is increasingly being transformed in ways, and by devices, that seem to come out of the pages of science fiction, even while the world itself is becoming a futuristic landscape. The result is that science fiction provides the most useful social theory, the only form that manages to be as radical as reality itself. Connected looks at how our networked environment has manifested itself in the work of J. G. Ballard, William S. Burroughs, Philip K. Dick, William Gibson, K. W. Jeter, and others. Shaviro focuses on science fiction not only as a form of cultural commentary but also as a prescient forum in which to explore the forces that are morphing our world into a sort of virtual reality game. Original and compelling, Connected shows how the continual experimentation of science fiction, like science and technology themselves, conjures the invisible social and economic forces that surround us.},
	language = {en},
	publisher = {University of Minnesota Press},
	author = {Shaviro, Steven},
	year = {2003},
	keywords = {Technology \& Engineering / Social Aspects},
}

@article{zhuetal2017,
	title = {Big learning with {Bayesian} methods},
	url = {http://arxiv.org/abs/1411.6370},
	abstract = {The explosive growth in data volume and the availability of cheap computing resources have sparked increasing interest in Big learning, an emerging subﬁeld that studies scalable machine learning algorithms, systems, and applications with Big Data. Bayesian methods represent one important class of statistical methods for machine learning, with substantial recent developments on adaptive, ﬂexible and scalable Bayesian learning. This article provides a survey of the recent advances in Big learning with Bayesian methods, termed Big Bayesian Learning, including nonparametric Bayesian methods for adaptively inferring model complexity, regularized Bayesian inference for improving the ﬂexibility via posterior regularization, and scalable algorithms and systems based on stochastic subsampling and distributed computing for dealing with large-scale applications. We also provide various new perspectives on the large-scale Bayesian modeling and inference.},
	language = {en},
	urldate = {2020-07-27},
	journal = {arXiv:1411.6370 [cs, stat]},
	author = {Zhu, Jun and Chen, Jianfei and Hu, Wenbo and Zhang, Bo},
	year = {2017},
	note = {arXiv: 1411.6370},
	keywords = {Computer Science - Machine Learning, F.1.2, G.3, Statistics - Applications, Statistics - Computation, Statistics - Machine Learning, Statistics - Methodology},
}

@book{walton2008,
	title = {Informal logic: {A} pragmatic approach},
	isbn = {978-1-139-47281-4},
	shorttitle = {Informal logic},
	abstract = {Second edition of the introductory guidebook to the basic principles of constructing sound arguments and criticising bad ones. Non-technical in approach, it is based on 186 examples, which Douglas Walton, a leading authority in the field of informal logic, discusses and evaluates in clear, illustrative detail. Walton explains how errors, fallacies, and other key failures of argument occur. He shows how correct uses of argument are based on sound strategies for reasoned persuasion and critical responses. This edition takes into account many developments in the field of argumentation study that have occurred since 1989, many created by the author. Drawing on these developments, Walton includes and analyzes 36 new topical examples and also brings in work on argumentation schemes. Ideally suited for use in courses in informal logic and introduction to philosophy, this book will also be valuable to students of pragmatics, rhetoric, and speech communication.},
	language = {en},
	publisher = {Cambridge University Press},
	author = {Walton, Douglas},
	year = {2008},
	keywords = {Philosophy / General, Philosophy / Logic},
}

@article{valverde-albacetepelaez-moreno2014,
	title = {100\% classification accuracy considered harmful: {The} normalized information transfer factor explains the accuracy paradox},
	volume = {9},
	issn = {1932-6203},
	shorttitle = {100\% classification accuracy considered harmful},
	url = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0084217},
	doi = {10.1371/journal.pone.0084217},
	abstract = {The most widely spread measure of performance, accuracy, suffers from a paradox: predictive models with a given level of accuracy may have greater predictive power than models with higher accuracy. Despite optimizing classification error rate, high accuracy models may fail to capture crucial information transfer in the classification task. We present evidence of this behavior by means of a combinatorial analysis where every possible contingency matrix of 2, 3 and 4 classes classifiers are depicted on the entropy triangle, a more reliable information-theoretic tool for classification assessment. Motivated by this, we develop from first principles a measure of classification performance that takes into consideration the information learned by classifiers. We are then able to obtain the entropy-modulated accuracy (EMA), a pessimistic estimate of the expected accuracy with the influence of the input distribution factored out, and the normalized information transfer factor (NIT), a measure of how efficient is the transmission of information from the input to the output set of classes. The EMA is a more natural measure of classification performance than accuracy when the heuristic to maximize is the transfer of information through the classifier instead of classification error count. The NIT factor measures the effectiveness of the learning process in classifiers and also makes it harder for them to “cheat” using techniques like specialization, while also promoting the interpretability of results. Their use is demonstrated in a mind reading task competition that aims at decoding the identity of a video stimulus based on magnetoencephalography recordings. We show how the EMA and the NIT factor reject rankings based in accuracy, choosing more meaningful and interpretable classifiers.},
	language = {en},
	number = {1},
	journal = {PLOS ONE},
	author = {Valverde-Albacete, Francisco J. and Peláez-Moreno, Carmen},
	year = {2014},
	keywords = {Discrete random variables, Entropy, Forecasting, Human performance, Information entropy, Machine learning, Magnetoencephalography, Sports},
	pages = {e84217},
}

@article{shanahan2010,
	title = {Changing the meaning of peer-to-peer? {Exploring} online comment spaces as sites of negotiated expertise},
	volume = {9},
	shorttitle = {Changing the meaning of peer-to-peer?},
	number = {1},
	journal = {Journal of Science Communication},
	author = {Shanahan, Marie-Claire},
	year = {2010},
	pages = {A01},
}

@article{rogers2021,
	title = {Changing the world by changing the data},
	url = {http://arxiv.org/abs/2105.13947},
	abstract = {NLP community is currently investing a lot more research and resources into development of deep learning models than training data. While we have made a lot of progress, it is now clear that our models learn all kinds of spurious patterns, social biases, and annotation artifacts. Algorithmic solutions have so far had limited success. An alternative that is being actively discussed is more careful design of datasets so as to deliver specific signals. This position paper maps out the arguments for and against data curation, and argues that fundamentally the point is moot: curation already is and will be happening, and it is changing the world. The question is only how much thought we want to invest into that process.},
	journal = {arXiv:2105.13947 [cs]},
	author = {Rogers, Anna},
	year = {2021},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
}

@article{riversweber2011,
	title = {Ecological, pedagogical, public rhetoric},
	volume = {63},
	issn = {0010-096X},
	abstract = {Public rhetoric pedagogy can benefit from an ecological perspective that sees change as advocated not through a single document but through multiple mundane and monumental texts. This article summarizes various approaches to rhetorical ecology, offers an ecological read of the Montgomery bus boycotts, and concludes with pedagogical insights on a first-year composition project emphasizing rhetorical ecologies.},
	number = {2},
	journal = {College Composition and Communication},
	author = {Rivers, Nathaniel A. and Weber, Ryan P.},
	year = {2011},
	pages = {187--218},
}

@article{omizo2020,
	series = {Composing {Algorithms}: {Writing} (with) {Rhetorical} {Machines}},
	title = {Machining topoi: {Tracking} premising in online discussion forums with automated rhetorical move analysis},
	volume = {57},
	issn = {8755-4615},
	shorttitle = {Machining topoi},
	url = {https://www.sciencedirect.com/science/article/pii/S8755461520300396},
	doi = {10.1016/j.compcom.2020.102578},
	abstract = {This article interrogates recent computational work on discovering and analyzing topoi through the use of topic modeling in the discipline of the literary digital humanities against the long history of topical research and pedagogy in rhetoric and composition. While significant work has been done in the literary digital humanities to advance the study of texts through topic modeling, this article argues that the emphasis on the textuality of topoi in computational research neglects situated rhetorical actions and the dynamics of audience interaction. In response to this deemphasis, this article proposes an algorithmic alternative to the identification and explanation of the rhetorical topoi through the integrated use of a computational rhetorical move classifier called the Faciloscope (Omizo et al., 2016) and the pattern-matching program, Docuscope (Kaufer and Ishizaki, 1998).},
	language = {en},
	urldate = {2021-05-25},
	journal = {Computers and Composition},
	author = {Omizo, Ryan M.},
	year = {2020},
	keywords = {Docuscope, Faciloscope, computational rhetoric, discussion forums, topoi},
	pages = {102578},
}

@article{oevermannziegler2018,
	title = {Automated classification of content components in technical communication},
	volume = {34},
	copyright = {© 2018 Wiley Periodicals, Inc.},
	issn = {1467-8640},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/coin.12157},
	doi = {https://doi.org/10.1111/coin.12157},
	abstract = {Automated classification is usually not adjusted to specialized domains due to a lack of suitable data collections and insufficient characterization of the domain-specific content and its effect on the classification process. This work describes an approach for the automated multiclass classification of content components used in technical communication based on a vector space model. We show that differences in the form and substance of content components require an adaption of document-based classification methods and validate our assumptions with multiple real-world data sets in 2 languages. As a result, we propose general adaptions on feature selection and token weighting, as well as new ideas for the measurement of classifier confidence and the semantic weighting of XML-based training data. We introduce several potential applications of our method and provide prototypical implementation. Our contribution beyond the state of the art is a dedicated procedure model for the automated classification of content components in technical communication, which outperforms current document-centered or domain-agnostic approaches.},
	language = {en},
	number = {1},
	urldate = {2021-05-25},
	journal = {Computational Intelligence},
	author = {Oevermann, Jan and Ziegler, Wolfgang},
	year = {2018},
	keywords = {content management, machine learning, technical communication, text classification},
	pages = {30--48},
}

@article{nerlichetal2012,
	title = {Climate in the news: {How} differences in media discourse between the {US} and {UK} reflect national priorities},
	volume = {6},
	issn = {1752-4032},
	shorttitle = {Climate in the news},
	url = {https://doi.org/10.1080/17524032.2011.644633},
	doi = {10.1080/17524032.2011.644633},
	abstract = {Studies dealing with media coverage of climate change have increased steadily over the last decade or so, alongside the media coverage of climate change itself. This article aims to contribute to this growing literature on two levels: to deepen understanding of distinctive patterns of language use across nations speaking a common language and to demonstrate the usefulness of a new approach for finding such patterns. Articles in The (London) Times and the New York Times, published between 2000 and 2009, were analyzed using methods related to computational linguistics. Results show that the US seemingly still constructs climate change as a problem, whereas the UK focuses on finding solutions for the (established) problem of climate change. This linguistic and conceptual gap may hamper mutual understanding and the crafting of global climate change mitigation policies.},
	number = {1},
	urldate = {2021-06-04},
	journal = {Environmental Communication},
	author = {Nerlich, Brigitte and Forsyth, Richard and Clarke, David},
	year = {2012},
	keywords = {Carbon, Climate Change, Computational Linguistics, Media, United Kingdom, United States},
	pages = {44--63},
}

@article{mcnelyetal2015,
	title = {Contemporary research methodologies in technical communication},
	volume = {24},
	issn = {1057-2252},
	url = {https://doi.org/10.1080/10572252.2015.975958},
	doi = {10.1080/10572252.2015.975958},
	number = {1},
	urldate = {2021-05-25},
	journal = {Technical Communication Quarterly},
	author = {McNely, Brian and Spinuzzi, Clay and Teston, Christa},
	year = {2015},
	pages = {1--13},
}

@article{majdikkeith2011,
	title = {Expertise as argument: {Authority}, democracy, and problem-solving},
	volume = {25},
	copyright = {All rights reserved},
	shorttitle = {Expertise as argument},
	number = {3},
	journal = {Argumentation},
	author = {Majdik, Zoltan P. and Keith, William M.},
	year = {2011},
	pages = {371--384},
}

@article{mackiewicz2010,
	title = {Assertions of expertise in online product reviews},
	volume = {24},
	number = {1},
	journal = {Journal of Business and Technical Communication},
	author = {Mackiewicz, Jo},
	year = {2010},
	pages = {3--28},
}

@misc{karani2020,
	title = {Introduction to word embedding and {Word2Vec}},
	url = {https://towardsdatascience.com/introduction-to-word-embedding-and-word2vec-652d0c2060fa},
	abstract = {Word embedding is one of the most popular representation of document vocabulary. It is capable of capturing context of a word in a…},
	language = {en},
	journal = {Medium},
	author = {Karani, Dhruvil},
	year = {2020},
}

@article{johnsonkhoshgoftaar2019,
	title = {Survey on deep learning with class imbalance},
	volume = {6},
	issn = {2196-1115},
	url = {https://doi.org/10.1186/s40537-019-0192-5},
	doi = {10.1186/s40537-019-0192-5},
	abstract = {The purpose of this study is to examine existing deep learning techniques for addressing class imbalanced data. Effective classification with imbalanced data is an important area of research, as high class imbalance is naturally inherent in many real-world applications, e.g., fraud detection and cancer detection. Moreover, highly imbalanced data poses added difficulty, as most learners will exhibit bias towards the majority class, and in extreme cases, may ignore the minority class altogether. Class imbalance has been studied thoroughly over the last two decades using traditional machine learning models, i.e. non-deep learning. Despite recent advances in deep learning, along with its increasing popularity, very little empirical work in the area of deep learning with class imbalance exists. Having achieved record-breaking performance results in several complex domains, investigating the use of deep neural networks for problems containing high levels of class imbalance is of great interest. Available studies regarding class imbalance and deep learning are surveyed in order to better understand the efficacy of deep learning when applied to class imbalanced data. This survey discusses the implementation details and experimental results for each study, and offers additional insight into their strengths and weaknesses. Several areas of focus include: data complexity, architectures tested, performance interpretation, ease of use, big data application, and generalization to other domains. We have found that research in this area is very limited, that most existing work focuses on computer vision tasks with convolutional neural networks, and that the effects of big data are rarely considered. Several traditional methods for class imbalance, e.g. data sampling and cost-sensitive learning, prove to be applicable in deep learning, while more advanced methods that exploit neural network feature learning abilities show promising results. The survey concludes with a discussion that highlights various gaps in deep learning from class imbalanced data for the purpose of guiding future research.},
	number = {1},
	urldate = {2021-02-06},
	journal = {Journal of Big Data},
	author = {Johnson, Justin M. and Khoshgoftaar, Taghi M.},
	year = {2019},
	keywords = {Big data, Class imbalance, Deep learning, Deep neural networks},
	pages = {1--54},
}

@article{jasanoff2003,
	title = {Breaking the waves in science studies: comment on {HM} {Collins} and {Robert} {Evans}, '{The} third wave of science studies'},
	volume = {33},
	shorttitle = {Breaking the waves in science studies},
	number = {3},
	journal = {Social studies of science},
	author = {Jasanoff, Sheila},
	year = {2003},
	pages = {389--400},
}

@book{hartelius2011,
	title = {The rhetoric of expertise},
	isbn = {978-0-7391-4703-0},
	abstract = {Reliance on expertise has become so commonplace in American culture that it is virtually impossible to avoid. Relying on expertise is one way we delegate the contents of our busy lives and defer to authority in the interest of being efficient. In The Rhetoric of Expertise, E. Johanna Hartelius investigates how expertise is negotiated as a function of the rhetorical situation, its participants and constraints. Specifically, she asks: What rhetorical strategies do different groups employ to compete for expert authority and legitimacy when they conflict with one another? Each chapter focuses on a particular context-politics, history, medicine, and information. By demonstrating that expertise is managed through argumentation, The Rhetoric of Expertise informs a number of practical issues: how the nation's political world is run, why some forms of medical expertise are deemed credible while others are derided, what the differences are between historical scholarship and the memory of lived experience, and why new information producers are causing such a stir.},
	language = {en},
	publisher = {Lexington Books},
	author = {Hartelius, E. Johanna},
	year = {2011},
	keywords = {Social Science / Media Studies},
}

@article{hartlind2011,
	title = {The rhetoric of {Islamic} activism: {A} {DICTION} study},
	volume = {4},
	issn = {1746-7586},
	shorttitle = {The rhetoric of {Islamic} activism},
	url = {https://doi.org/10.1080/17467586.2011.627934},
	doi = {10.1080/17467586.2011.627934},
	abstract = {Given the paucity of understanding in the West regarding Middle Eastern discourse, this study provides a careful description of Islamic activist rhetoric. Using DICTION, a program that calculates some 40 different stylistic variables and 5 master variables, we compared the rhetoric of Western politicians, protestors, preachers, and pundits to that of Islamic activists. Relative to the West, the Islamic sample was relatively hopeful and communal, extremely doctrinaire, and often had a transcendental tone. Analysis within the Islamic sample showed it to be more flexible and variegated than might have been expected. Intriguingly, the rhetoric of violent Islamists was more optimistic than that of their nonviolent brethren. The violent groups were more likely to embrace charismatic authority and to substitute ideology for practicality. In short, our findings confirm some popular expectations of Muslim discourse but also call into question a number of received truths, all of which suggests that much more needs to be learned about the voices of Islam.},
	number = {2},
	urldate = {2020-07-27},
	journal = {Dynamics of Asymmetric Conflict},
	author = {Hart, Roderick P. and Lind, Colene J.},
	year = {2011},
	keywords = {Islam, Middle East, activism, politics, rhetoric, terrorism, violence},
	pages = {113--125},
}

@incollection{hart2015,
	title = {Genre and automated text analysis: {A} demonstration},
	isbn = {978-0-226-17669-7},
	language = {en},
	booktitle = {Rhetoric and the {Digital} {Humanities}},
	publisher = {University of Chicago Press},
	author = {Hart, Roderick P.},
	editor = {Ridolfo, Jim and Hart-Davidson, William},
	year = {2015},
	keywords = {Language Arts \& Disciplines / Library \& Information Science / Digital \& Online Resources, Language Arts \& Disciplines / Rhetoric, Literary Criticism / General},
	pages = {152--168},
}

@article{gieryn1983,
	title = {Boundary-work and the demarcation of science from non-science: {Strains} and interests in professional ideologies of scientists},
	shorttitle = {Boundary-work and the demarcation of science from non-science},
	journal = {American Sociological Review},
	author = {Gieryn, Thomas F.},
	year = {1983},
	pages = {781--795},
}

@article{guldi2018,
	title = {Critical search: {A} procedure for guided reading in large-scale textual corpora},
	volume = {1},
	doi = {http://doi.org/10.22148/16.030},
	language = {en},
	number = {2},
	journal = {Journal of Cultural Analytics},
	author = {Guldi, Jo},
	year = {2018},
	pages = {36},
}

@article{grundmannkrishnamurthy2010,
	title = {The discourse of climate change: {A} corpus-based approach},
	volume = {4},
	shorttitle = {The discourse of climate change},
	number = {2},
	journal = {Critical Approaches to Discourse Analysis Across Disciplines},
	author = {Grundmann, Reiner and Krishnamurthy, Ramesh},
	year = {2010},
	pages = {125--146},
}

@article{graham2020,
	title = {The opioid epidemic and the pursuit of moral medicine: {A} computational-rhetorical analysis},
	volume = {38},
	shorttitle = {The opioid epidemic and the pursuit of moral medicine},
	doi = {10.1177/0741088320944918},
	number = {1},
	journal = {Written Communication},
	author = {Graham, S. Scott},
	year = {2020},
	pages = {3--30},
}

@book{giddens1991,
	title = {Modernity and self-identity: {Self} and society in the late modern age},
	shorttitle = {Modernity and self-identity},
	publisher = {Stanford University Press},
	author = {Giddens, Anthony},
	year = {1991},
}

@article{galegheretal1998,
	title = {Legitimacy, authority, and community in electronic support groups},
	volume = {15},
	number = {4},
	journal = {Written communication},
	author = {Galegher, Jolene and Sproull, Lee and Kiesler, Sara},
	year = {1998},
	pages = {493--530},
}

@inproceedings{benderetal2011,
	title = {Annotating social acts: {Authority} claims and alignment moves in {Wikipedia} {Talk} pages},
	shorttitle = {Annotating social acts},
	booktitle = {Proceedings of the {Workshop} on {Language} in {Social} {Media} ({LSM} 2011)},
	author = {Bender, Emily M. and Morgan, Jonathan T. and Oxley, Meghan and Zachry, Mark and Hutchinson, Brian and Marin, Alex and Zhang, Bin and Ostendorf, Mari},
	year = {2011},
	pages = {48--57},
}

@article{edbauer2005,
	title = {Unframing models of public distribution: {From} rhetorical situation to rhetorical ecologies},
	volume = {35},
	issn = {0277-3945},
	shorttitle = {Unframing models of public distribution},
	url = {https://doi.org/10.1080/02773940509391320},
	doi = {10.1080/02773940509391320},
	abstract = {Whereas earlier work on rhetorical situation focuses upon, the elements of audience, exigence, and constraints, this article argues that rhetorical situations operate within a network of lived practical consciousness or structures of feeling. Placing the rhetorical “elements” within this wider context destabilizes the discrete borders of a rhetorical situation. As an example of this wider context, this article explores the public rhetoric surrounding issues of urban sprawl in Austin, Texas. While public rhetorical movements can be seen as a response to the “exigence” of overdevelopment, it is also possible to situate the exigence's evocation within a wider context of affective ecologies comprised of material experiences and public feelings.},
	number = {4},
	urldate = {2020-07-23},
	journal = {Rhetoric Society Quarterly},
	author = {Edbauer, Jenny},
	year = {2005},
	pages = {5--24},
}

@article{dubremetznivre2018,
	title = {Rhetorical figure detection: chiasmus, epanaphora, epiphora},
	volume = {5},
	issn = {2297-2668},
	shorttitle = {Rhetorical figure detection},
	url = {https://www.frontiersin.org/articles/10.3389/fdigh.2018.00010/full},
	doi = {10.3389/fdigh.2018.00010},
	abstract = {Rhetorical figures are valuable linguistic data for literary analysis. In this article, we target the detection of three rhetorical figures that belong to the family of repetitive figures: chiasmus (I go where I please, and I please where I go.), epanaphora also called anaphora (“Poor old European Commission! Poor old European Council.”) and epiphora (“This house is mine. This car is mine. You are mine.”). Detecting repetition of words is easy for a computer but detecting only the ones provoking a rhetorical effect is difficult because of many accidental and irrelevant repetitions. For all figures, we train a log-linear classifier on a corpus of political debates. The corpus is only very partially annotated, but we nevertheless obtain good results, with more than 50\% precision for all figures. We then apply our models to totally different genres and perform a comparative analysis, by comparing corpora of fiction, science and quotes. Thanks to the automatic detection of rhetorical figures, we discover that chiasmus is more likely to appear in the scientific context whereas epanaphora and epiphora are more common in fiction.},
	language = {English},
	journal = {Frontiers in Digital Humanities},
	author = {Dubremetz, Marie and Nivre, Joakim},
	year = {2018},
	keywords = {Antimetabole, Chiasmus, Epiphora, Rhetorical Device, computational stylistics., epanaphora, repetitive figures},
	pages = {1--16},
}

@book{corbettconnors1999,
	title = {Classical rhetoric for the modern student},
	isbn = {978-0-19-511542-0},
	abstract = {Widely used in advanced composition and writing courses, Classical Rhetoric for the Modern Student discusses the three vital components of classical rhetoric--argument, arrangement, and style--bringing these elements to life and demonstrating their effective use in yesterday's and today's writing. Presenting its subject in five parts, the text provides grounding in the elements and applications of classical rhetoric; the strategies and tactics of argumentation; the effective presentation and organization of discourses; the development of power, grace, and felicity in expression; and the history of rhetorical principles. Numerous examples of classic and contemporary rhetoric, from paragraphs to complete essays, appear throughout the book, many followed by detailed analyses.  The fourth edition of Classical Rhetoric for the Modern Student features a new section on the Progymnasmata (classical composition exercises), a new analysis of a color advertisement in the Introduction, an updated survey of the history of rhetoric, and an updated section on "External Aids to Invention."},
	language = {en},
	publisher = {Oxford University Press},
	author = {Corbett, Edward P. J. and Connors, Robert J.},
	year = {1999},
	keywords = {Language Arts \& Disciplines / Rhetoric},
}

@article{collinsevans2002,
	title = {The third wave of science studies: {Studies} of expertise and experience},
	volume = {32},
	shorttitle = {The third wave of science studies},
	number = {2},
	journal = {Social Studies of Science},
	author = {Collins, Harry M. and Evans, Robert},
	year = {2002},
	pages = {235--296},
}

@misc{ananthaswamy2021,
	title = {Artificial neural nets finally yield clues to how brains learn},
	url = {https://www.quantamagazine.org/artificial-neural-nets-finally-yield-clues-to-how-brains-learn-20210218/},
	abstract = {The learning algorithm that enables the runaway success of deep neural networks doesn't work in biological brains, but researchers are finding alternatives that could.},
	language = {en},
	journal = {Quanta Magazine},
	author = {Ananthaswamy, Anil},
	year = {2021},
}

@misc{alammar2018,
	title = {The illustrated {BERT}, {ELMo}, and co. ({How} {NLP} cracked transfer learning)},
	url = {http://jalammar.github.io/illustrated-bert/},
	abstract = {Discussions:
Hacker News (98 points, 19 comments), Reddit r/MachineLearning (164 points, 20 comments)


Translations: Chinese (Simplified), French, Japanese, Korean, Persian, Russian

The year 2018 has been an inflection point for machine learning models handling text (or more accurately, Natural Language Processing or NLP for short). Our conceptual understanding of how best to represent words and sentences in a way that best captures underlying meanings and relationships is rapidly evolving. Moreover, the NLP community has been putting forward incredibly powerful components that you can freely download and use in your own models and pipelines (It’s been referred to as NLP’s ImageNet moment, referencing how years ago similar developments accelerated the development of machine learning in Computer Vision tasks).},
	author = {Alammar, Jay},
	year = {2018},
}

@incollection{prelli1997,
	title = {The rhetorical construction of scientific ethos},
	booktitle = {Landmark essays on rhetoric of science: {Case} studies},
	publisher = {Lawrence Erlbaum},
	author = {Prelli, Lawrence},
	editor = {Harris, Randy Allen},
	year = {1997},
}

@article{gallagheretal2020,
	title = {Peering into the internet abyss: {Using} big data audience analysis to understand online comments},
	volume = {29},
	issn = {1057-2252},
	shorttitle = {Peering into the internet abyss},
	url = {https://doi.org/10.1080/10572252.2019.1634766},
	doi = {10.1080/10572252.2019.1634766},
	abstract = {This article offers a methodology for conducting large-scale audience analysis called “big data audience analysis” (BDAA). BDAA uses distant reading and thin description to examine a large corpus of text data from online audiences. In this article, that corpus is approximately 450,000 online reader comments. We analyze this corpus through sentiment analysis, statistical analysis, and geolocation to identify trends and patterns in large datasets. BDAA can better prepare TPC researchers for large-scale audience studies.},
	number = {2},
	urldate = {2021-06-03},
	journal = {Technical Communication Quarterly},
	author = {Gallagher, John R. and Chen, Yinyin and Wagner, Kyle and Wang, Xuan and Zeng, Jingyi and Kong, Alyssa Lingyi},
	year = {2020},
	keywords = {Digital technologies, experimental research, research methods, usability studies, visual rhetoric/visualization techniques},
	pages = {155--173},
}

@inproceedings{benderetal2021,
	address = {New York},
	series = {{FAccT} '21},
	title = {On the dangers of stochastic parrots: {Can} language models be too big?},
	isbn = {978-1-4503-8309-7},
	shorttitle = {On the dangers of stochastic parrots},
	url = {https://doi.org/10.1145/3442188.3445922},
	doi = {10.1145/3442188.3445922},
	abstract = {The past 3 years of work in NLP have been characterized by the development and deployment of ever larger language models, especially for English. BERT, its variants, GPT-2/3, and others, most recently Switch-C, have pushed the boundaries of the possible both through architectural innovations and through sheer size. Using these pretrained models and the methodology of fine-tuning them for specific tasks, researchers have extended the state of the art on a wide array of tasks as measured by leaderboards on specific benchmarks for English. In this paper, we take a step back and ask: How big is too big? What are the possible risks associated with this technology and what paths are available for mitigating those risks? We provide recommendations including weighing the environmental and financial costs first, investing resources into curating and carefully documenting datasets rather than ingesting everything on the web, carrying out pre-development exercises evaluating how the planned approach fits into research and development goals and supports stakeholder values, and encouraging research directions beyond ever larger language models.},
	urldate = {2021-06-01},
	booktitle = {Proceedings of the 2021 {ACM} {Conference} on {Fairness}, {Accountability}, and {Transparency}},
	publisher = {Association for Computing Machinery},
	author = {Bender, Emily M. and Gebru, Timnit and McMillan-Major, Angelina and Shmitchell, Shmargaret},
	month = mar,
	year = {2021},
	pages = {610--623},
}

@article{hartelius2010,
	title = {Wikipedia and the emergence of dialogic expertise},
	volume = {75},
	issn = {1041-794X},
	url = {https://doi.org/10.1080/10417940903377169},
	doi = {10.1080/10417940903377169},
	abstract = {Wikipedia's popularity as an online encyclopedia calls attention to fundamental assumptions about the management and dissemination of information. Drawing on a Bakhtinian framework, this article posits a model of dialogic expertise. Specifically, it argues that, by facilitating an ongoing chain of interdependent and multivocal “utterances,” Wikipedia challenges traditional “monologic” expertise. Nonetheless, the site's purportedly democratic defiance of knowledge elites (of encyclopedic publishing, academe, etc.) is compromised by the establishment of a “technocratic” hierarchy. Implications extend to the scholarly debate surrounding dialogue and rhetoric and to our understanding of Wikipedia's success in the context of a cultural anxiety—Americans are at once dependent on an extensive system of experts and uneasy about the deferential distribution of power within that system.},
	number = {5},
	urldate = {2021-05-28},
	journal = {Southern Communication Journal},
	author = {Hartelius, E. Johanna},
	year = {2010},
	pages = {505--526},
}

@article{devasto2016,
	title = {Being expert: {L}’{Aquila} and issues of inclusion in science-policy decision making},
	volume = {30},
	shorttitle = {Being expert},
	number = {4},
	journal = {Social Epistemology},
	author = {DeVasto, Danielle},
	year = {2016},
	pages = {372--397},
}

@inproceedings{larsonetal2016,
	address = {Silver Spring MD USA},
	title = {Use what you choose: applying computational methods to genre studies in technical communication},
	isbn = {978-1-4503-4495-1},
	shorttitle = {Use what you choose},
	url = {https://dl.acm.org/doi/10.1145/2987592.2987603},
	doi = {10.1145/2987592.2987603},
	abstract = {This paper reports on the results of an intensive application development workshop held in the summer of 2015 during which a group of thirteen researchers came together to explore the use of machine-learning algorithms in technical communication. To do this we analyzed Amazon.com consumer electronic product customer reviews to reevaluate a central concept in North American Genre Theory: stable genre structures arise from recurring social actions ([1][2][3][4][5]). We discovered evidence of genre hybridity in the signals of instructional genres embedded into customer reviews. Our paper discusses the creation of a prototype web application, “Use What You Choose” (UWYC), which sorts the natural language text of Amazon reviews into two categories: instructionally-weighed reviews (e.g., reviews that contain operational information about products) and noninstructionally-weighed reviews (those that evaluate the quality of the product). Our results contribute to rhetorical genre theory and offer ideas on applying genre theory to inform application design for users of information services.},
	language = {en},
	urldate = {2021-05-25},
	booktitle = {Proceedings of the 34th {ACM} {International} {Conference} on the {Design} of {Communication}},
	publisher = {ACM},
	author = {Larson, Brian and Hart-Davidson, William and Walker, Kenneth C. and Walls, Douglas M. and Omizo, Ryan},
	year = {2016},
	pages = {1--8},
}

@article{miller1984,
	title = {Genre as social action},
	volume = {70},
	number = {2},
	journal = {Quarterly Journal of Speech},
	author = {Miller, Carolyn R.},
	year = {1984},
	pages = {151--167},
}

@article{majdikkeith2011a,
	title = {The problem of pluralistic expertise: {A} {Wittgensteinian} approach to the rhetorical basis of expertise},
	volume = {25},
	copyright = {All rights reserved},
	shorttitle = {The problem of pluralistic expertise},
	number = {3},
	journal = {Social Epistemology},
	author = {Majdik, Zoltan P. and Keith, William M.},
	year = {2011},
	pages = {275--290},
}

@article{walton_how_2019,
	title = {How {Computational} {Tools} {Can} {Help} {Rhetoric} and {Informal} {Logic} with {Argument} {Invention}},
	volume = {33},
	issn = {0920427X},
	url = {https://ezproxy.lib.ndsu.nodak.edu/login?url=https://search.ebscohost.com/login.aspx?direct=true&db=ufh&AN=136223717&site=ehost-live&scope=site},
	doi = {10.1007/s10503-017-9439-5},
	abstract = {This paper compares the features and methods of the two leading implemented systems that offer a tool for helping a user to find or invent arguments to support or attack a designated conclusion, the Carneades Argumentation System and the IBM Watson Debater tool. The central aim is to contribute to the understanding of scholars in informal logic, rhetoric and argumentation on how these two software systems can be useful for them. One contribution of the paper is to explain to these potential users how the two tools are applicable to the task of inventing arguments by using some simple illustrative examples. Another is to redefine the structure of argument invention as a procedure.},
	number = {2},
	urldate = {2021-05-06},
	journal = {Argumentation},
	author = {Walton, Douglas and Gordon, Thomas F.},
	month = jun,
	year = {2019},
	note = {Publisher: Springer Nature},
	keywords = {Argument mining, Artificial intelligence, Computational linguistics, Computer software, Debate, Inventions, Rhetorical analysis, Rhetorical invention},
	pages = {269--295},
}

@article{burscher_teaching_2014,
	title = {Teaching the {Computer} to {Code} {Frames} in {News}: {Comparing} {Two} {Supervised} {Machine} {Learning} {Approaches} to {Frame} {Analysis}},
	volume = {8},
	issn = {19312458},
	shorttitle = {Teaching the {Computer} to {Code} {Frames} in {News}},
	url = {https://ezproxy.lib.ndsu.nodak.edu/login?url=https://search.ebscohost.com/login.aspx?direct=true&db=ufh&AN=97586249&site=ehost-live&scope=site},
	doi = {10.1080/19312458.2014.937527},
	abstract = {We explore the application of supervised machine learning (SML) to frame coding. By automating the coding of frames in news, SML facilitates the incorporation of large-scale content analysis into framing research, even if financial resources are scarce. This furthers a more integrated investigation of framing processes conceptually as well as methodologically. We conduct several experiments in which we automate the coding of four generic frames that are operationalised as a set of indicator questions. In doing so, we compare two approaches to modelling the coherence between indicator questions and frames as an SML task. The results of our experiments show that SML is well suited to automate frame coding but that coding performance is dependent on the way SML is implemented.},
	number = {3},
	urldate = {2021-05-06},
	journal = {Communication Methods \& Measures},
	author = {Burscher, Björn and Odijk, Daan and Vliegenthart, Rens and de Rijke, Maarten and de Vreese, Claes H.},
	month = jul,
	year = {2014},
	note = {Publisher: Routledge},
	keywords = {Coding theory, Computer training, Frames (Social sciences), Machine learning, Machine theory},
	pages = {190--206},
}

@misc{sarwan2017,
	title = {Understanding word embeddings: {From} word2vec to count vectors},
	shorttitle = {Understanding word embeddings},
	url = {https://www.analyticsvidhya.com/blog/2017/06/word-embeddings-count-word2veec/},
	abstract = {Word embeddings are techniques used in natural language processing. This includes tools \& techiniques like word2vec, TD-IDF, count vectors, etc.},
	journal = {Analytics Vidhya},
	author = {Sarwan, Neeraj Singh},
	year = {2017},
}

@misc{latysheva2019,
	title = {Why do we use word embeddings in {NLP}?},
	url = {https://towardsdatascience.com/why-do-we-use-embeddings-in-nlp-2f20e1b632d2},
	abstract = {An introduction  to the difficulties of text representation in machine learning.},
	language = {en},
	journal = {Medium},
	author = {Latysheva, Natasha},
	month = sep,
	year = {2019},
}

@misc{noauthor_topic_2012,
	title = {Topic modeling made just simple enough.},
	url = {https://tedunderwood.com/2012/04/07/topic-modeling-made-just-simple-enough/},
	abstract = {Right now, humanists often have to take topic modeling on faith. There are several good posts out there that introduce the principle of the thing (by Matt Jockers, for instance, and Scott Weingart)…},
	language = {en},
	urldate = {2021-04-28},
	journal = {The Stone and the Shell},
	month = apr,
	year = {2012},
}

@article{cameron_twitter_2021,
	title = {Twitter {Users}’ {Displays} of {Affect} in the {Global} {Warming} {Debate}},
	issn = {0047-2816},
	url = {https://doi.org/10.1177/00472816211007804},
	doi = {10.1177/00472816211007804},
	abstract = {This article engages with recent discussions in the field of technical communication that call for climate change research that moves beyond the believer/denier dichotomy. For this study, our research team coded 900 tweets about climate change and global warming for different emotions in order to understand how Twitter users rely on affect rhetorically. Our findings use quantitative content analysis to challenge current assumptions about writing and affect on social media, and our results indicate a number of arenas for future research on affect, global warming, and rhetoric.},
	language = {en},
	urldate = {2021-04-18},
	journal = {Journal of Technical Writing and Communication},
	author = {Cameron, Shanna and Russell, Alexandra and Brake, Luke and Fredlund, Katherine and Morris, Angela},
	month = apr,
	year = {2021},
	note = {Publisher: SAGE Publications Inc},
	keywords = {Twitter, affect, digital media, global warming, quantitative content analysis},
	pages = {00472816211007804},
}

@article{bruining_interrogating_2016,
	title = {Interrogating the {Founding} {Gestures} of the {New} {Materialism}},
	volume = {22},
	copyright = {Copyright (c) 2016 Dennis Bruining},
	issn = {1837-8692},
	url = {https://epress.lib.uts.edu.au/journals/index.php/csrj/article/view/4461},
	doi = {10.5130/csr.v22i2.4461},
	language = {en},
	number = {2},
	urldate = {2021-04-16},
	journal = {Cultural Studies Review},
	author = {Bruining, Dennis},
	month = nov,
	year = {2016},
	note = {Number: 2},
	keywords = {New materialism, constructionism, materiality, poststructuralist feminism, representationalism},
	pages = {21--40--21--40},
}

@article{pflugfelder_rhetorics_2015,
	title = {Rhetoric’s {New} {Materialism}: {From} {Micro}-{Rhetoric} to {Microbrew}},
	volume = {45},
	issn = {0277-3945},
	shorttitle = {Rhetoric’s {New} {Materialism}},
	url = {https://doi.org/10.1080/02773945.2015.1082616},
	doi = {10.1080/02773945.2015.1082616},
	abstract = {Increasingly, rhetoricians have taken up the task of understanding how rhetoric is applicable to material conditions, yet have found difficulty in approaching the rhetoric that exists between nonhumans. While the debate over the size of rhetoric, big or small, has often dominated discussions, the concern over size is less important than the relationship between rhetoric and materiality. Both “rhetorical materialism” and “rhetoric’s materiality” approaches see nonhuman objects as subsumed in symbolic representations and human-centric worldviews. This essay suggests a micro-rhetorical stance, which avoids discussions over size and builds upon existing formulations of exploratory, nonhuman rhetorics. A micro-rhetoric allows for concepts not previously thought of as rhetorical, such as hyle, which can be used to identify persuasive elements within nonhuman relations. To show how hyle can be used in a micro-rhetorical investigation, this essay offers a brief analysis of the material persuasions involved in the design of a microbrewery malting system.},
	number = {5},
	urldate = {2021-04-16},
	journal = {Rhetoric Society Quarterly},
	author = {Pflugfelder, Ehren Helmut},
	month = oct,
	year = {2015},
	note = {Publisher: Routledge
\_eprint: https://doi.org/10.1080/02773945.2015.1082616},
	pages = {441--461},
}

@article{greene_another_1998,
	title = {Another materialist rhetoric},
	volume = {15},
	issn = {0739-3180},
	url = {https://doi.org/10.1080/15295039809367031},
	doi = {10.1080/15295039809367031},
	abstract = {This paper argues for a new materialism. Rhetorical studies can achieve a new materialism by emphasizing how rhetoric traverses a governing apparatus as a technology of deliberation. As such, rhetoric makes possible the ability to judge and plan reality in order to police a population. To achieve this new materialism, I argue that rhetorical studies will need to abandon a logic of representation for a logic of articulation to better account for how rhetorical practices distribute different elements into a functioning network of power.},
	number = {1},
	urldate = {2021-04-16},
	journal = {Critical Studies in Mass Communication},
	author = {Greene, Ronald Walter},
	month = mar,
	year = {1998},
	note = {Publisher: Routledge
\_eprint: https://doi.org/10.1080/15295039809367031},
	pages = {21--40},
}

@article{vanderheletal2018,
	title = {Tipping points and climate change: {Metaphor} between science and the media},
	volume = {12},
	shorttitle = {Tipping points and climate change},
	number = {5},
	journal = {Environmental Communication},
	author = {van der Hel, Sandra and Hellsten, Iina and Steen, Gerard},
	year = {2018},
	pages = {605--620},
}

@book{latourwoolgar2013,
	title = {Laboratory life: {The} construction of scientific facts},
	isbn = {978-1-4008-2041-2},
	shorttitle = {Laboratory life},
	abstract = {This highly original work presents laboratory science in a deliberately skeptical way: as an anthropological approach to the culture of the scientist. Drawing on recent work in literary criticism, the authors study how the social world of the laboratory produces papers and other "texts,"' and how the scientific vision of reality becomes that set of statements considered, for the time being, too expensive to change. The book is based on field work done by Bruno Latour in Roger Guillemin's laboratory at the Salk Institute and provides an important link between the sociology of modern sciences and laboratory studies in the history of science.},
	language = {en},
	publisher = {Princeton University Press},
	author = {Latour, Bruno and Woolgar, Steve},
	year = {2013},
	keywords = {Social Science / Anthropology / General},
}

@article{deseretal2012,
	title = {Communication of the role of natural variability in future {North} {American} climate},
	volume = {2},
	copyright = {2012 Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
	issn = {1758-6798},
	url = {https://www.nature.com/articles/nclimate1562},
	doi = {10.1038/nclimate1562},
	abstract = {As climate models improve, decision-makers' expectations for accurate climate predictions are growing. Natural climate variability, however, limits climate predictability and hampers the ability to guide adaptation in many regions such as North America. Scientists, policymakers and the public need to improve communication and avoid raising expectations for accurate regional predictions everywhere.},
	language = {en},
	number = {11},
	journal = {Nature Climate Change},
	author = {Deser, Clara and Knutti, Reto and Solomon, Susan and Phillips, Adam S.},
	month = nov,
	year = {2012},
	pages = {775--779},
}

@article{kesslergraham2018,
	title = {Terminal node problems: {ANT} 2.0 and prescription drug labels},
	volume = {27},
	issn = {1057-2252, 1542-7625},
	shorttitle = {Terminal node problems},
	url = {https://www.tandfonline.com/doi/full/10.1080/10572252.2018.1425482},
	doi = {10.1080/10572252.2018.1425482},
	abstract = {This article examines prescription drug labels (PDLs) via an actor-network theory analysis to demonstrate current challenges with technical communication (TC) scholars’ appropriation of actor-network theory. The authors demonstrate that the complexity of the PDL network requires a more nuanced deployment of actor-network theory notions of durability and synchronicity. Specifically, the authors suggest that diachronic approaches to networks enable a more comprehensive understanding in ways that synchronic approaches cannot.},
	language = {en},
	number = {2},
	urldate = {2020-07-24},
	journal = {Technical Communication Quarterly},
	author = {Kessler, Molly M. and Graham, S. Scott},
	year = {2018},
	pages = {121--136},
}

@article{grahametal2015,
	title = {Statistical genre analysis: {Toward} big data methodologies in technical communication},
	volume = {24},
	issn = {1057-2252},
	shorttitle = {Statistical genre analysis},
	url = {https://doi.org/10.1080/10572252.2015.975955},
	doi = {10.1080/10572252.2015.975955},
	abstract = {This article pilots a study in statistical genre analysis, a mixed-method approach for (a) identifying conventional responses as a statistical distribution within a big data set and (b) assessing which deviations from the conventional might be more effective for changes in audience, purpose, or context. The study assesses pharmaceutical sponsor presentations at the Food and Drug Administration (FDA) drug advisory committee meetings. Preliminary findings indicate the need for changes to FDA conflict-of-interest policies.},
	number = {1},
	urldate = {2020-03-26},
	journal = {Technical Communication Quarterly},
	author = {Graham, S. Scott and Kim, Sang-Yeon and DeVasto, Danielle M. and Keith, William},
	year = {2015},
	keywords = {big data, genre analysis, pharmaceuticals, quantitative methods, science policy},
	pages = {70--104},
}

@inproceedings{yuetal2019,
	address = {Hong Kong, China},
	title = {Detecting {Causal} {Language} {Use} in {Science} {Findings}},
	url = {https://www.aclweb.org/anthology/D19-1473},
	doi = {10.18653/v1/D19-1473},
	abstract = {Causal interpretation of correlational findings from observational studies has been a major type of misinformation in science communication. Prior studies on identifying inappropriate use of causal language relied on manual content analysis, which is not scalable for examining a large volume of science publications. In this study, we first annotated a corpus of over 3,000 PubMed research conclusion sentences, then developed a BERT-based prediction model that classifies conclusion sentences into “no relationship”, “correlational”, “conditional causal”, and “direct causal” categories, achieving an accuracy of 0.90 and a macro-F1 of 0.88. We then applied the prediction model to measure the causal language use in the research conclusions of about 38,000 observational studies in PubMed. The prediction result shows that 21.7\% studies used direct causal language exclusively in their conclusions, and 32.4\% used some direct causal language. We also found that the ratio of causal language use differs among authors from different countries, challenging the notion of a shared consensus on causal language use in the global science community. Our prediction model could also be used to help identify the inappropriate use of causal language in science publications.},
	urldate = {2021-04-06},
	booktitle = {Proceedings of the 2019 {Conference} on {Empirical} {Methods} in {Natural} {Language} {Processing} and the 9th {International} {Joint} {Conference} on {Natural} {Language} {Processing} ({EMNLP}-{IJCNLP})},
	publisher = {Association for Computational Linguistics},
	author = {Yu, Bei and Li, Yingya and Wang, Jun},
	month = nov,
	year = {2019},
	pages = {4664--4674},
}

@article{schultheiskjelvik2020,
	title = {Using {Messy}, {Authentic} {Data} to {Promote} {Data} {Literacy} \& {Reveal} the {Nature} of {Science}},
	volume = {82},
	issn = {0002-7685},
	url = {https://doi.org/10.1525/abt.2020.82.7.439},
	doi = {10.1525/abt.2020.82.7.439},
	abstract = {Authentic, “messy data” contain variability that comes from many sources, such as natural variation in nature, chance occurrences during research, and human error. It is this messiness that both deters potential users of authentic data and gives data the power to create unique learning opportunities that reveal the nature of science itself. While the value of bringing contemporary research and messy data into the classroom is recognized, implementation can seem overwhelming. We discuss the importance of frequent interactions with messy data throughout K–16 science education as a mechanism for students to engage in the practices of science, such as visualizing, analyzing, and interpreting data. Next, we describe strategies to help facilitate the use of messy data in the classroom while building complexity over time. Finally, we outline one potential sequence of activities, with specific examples, to highlight how various activity types can be used to scaffold students' interactions with messy data.},
	number = {7},
	urldate = {2021-04-06},
	journal = {The American Biology Teacher},
	author = {Schultheis, Elizabeth H. and Kjelvik, Melissa K.},
	month = sep,
	year = {2020},
	pages = {439--446},
}

@misc{gmt_stop_nodate,
	title = {Stop {Calling} {Everything} {AI}, {Machine}-{Learning} {Pioneer} {Says} - {IEEE} {Spectrum}},
	url = {https://spectrum.ieee.org/the-institute/ieee-member-news/stop-calling-everything-ai-machinelearning-pioneer-says},
	language = {en},
	urldate = {2021-04-05},
	journal = {IEEE Spectrum: Technology, Engineering, and Science News},
	author = {GMT, Posted 31 Mar 2021 {\textbar} 17:00},
}

@article{greene_rhetoric_2004,
	title = {Rhetoric and {Capitalism}: {Rhetorical} {Agency} as {Communicative} {Labor}},
	volume = {37},
	issn = {0031-8213},
	shorttitle = {Rhetoric and {Capitalism}},
	url = {https://www.jstor.org/stable/40238183},
	number = {3},
	urldate = {2021-04-05},
	journal = {Philosophy \& Rhetoric},
	author = {Greene, Ronald Walter},
	year = {2004},
	note = {Publisher: Penn State University Press},
	pages = {188--206},
}

@article{leff_tradition_2003,
	title = {Tradition and {Agency} in {Humanistic} {Rhetoric}},
	volume = {36},
	issn = {0031-8213},
	url = {https://www.jstor.org/stable/40238144},
	number = {2},
	urldate = {2021-04-05},
	journal = {Philosophy \& Rhetoric},
	author = {Leff, Michael},
	year = {2003},
	note = {Publisher: Penn State University Press},
	pages = {135--147},
}

@article{truscello_rhetorical_2005,
	title = {The {Rhetorical} {Ecology} of the {Technical} {Effect}},
	volume = {14},
	issn = {1057-2252},
	url = {https://doi.org/10.1207/s15427625tcq1403_13},
	doi = {10.1207/s15427625tcq1403_13},
	abstract = {This article calls for close attention to the current moment when many technologies are becoming routine, occupying a space between "unknown and unnoticed," and for formation of a digital rhetoric that addresses software's liminality, ubiquity, and exteriority. It briefly examines the emerging discourse of the Free and Open Source Software movements and suggests that a closer alignment with software studies in coming years will be mutually beneficial to both fields.},
	number = {3},
	urldate = {2021-04-05},
	journal = {Technical Communication Quarterly},
	author = {Truscello, Michael},
	month = jul,
	year = {2005},
	note = {Publisher: Routledge
\_eprint: https://doi.org/10.1207/s15427625tcq1403\_13},
	pages = {345--351},
}

@article{wheeler_mining_2018,
	title = {Mining the {First} 100 {Days}: {Human} and {Data} {Ethics} in {Twitter} research},
	volume = {6},
	copyright = {Authors who publish with this journal agree to the following terms:    Authors retain copyright and grant the journal right of first publication with the work simultaneously licensed under a  Creative Commons Attribution License  that allows others to share the work with an acknowledgement of the work's authorship and initial publication in this journal.  Authors are able to enter into separate, additional contractual arrangements for the non-exclusive distribution of the journal's published version of the work (e.g., post it to an institutional repository or publish it in a book), with an acknowledgement of its initial publication in this journal.  Authors are permitted and encouraged to post their work online (e.g., in institutional repositories or on their website) prior to and during the submission process, as it can lead to productive exchanges, as well as earlier and greater citation of published work (See  The Effect of Open Access ).  All third-party images reproduced on this journal are shared under Educational Fair Use. For more information on  Educational Fair Use , please see  this useful checklist prepared by Columbia University Libraries .   All copyright  of third-party content posted here for research purposes belongs to its original owners.  Unless otherwise stated all references to characters and comic art presented on this journal are ©, ® or ™ of their respective owners. No challenge to any owner’s rights is intended or should be inferred.},
	issn = {2162-3309},
	shorttitle = {Mining the {First} 100 {Days}},
	url = {http://jlsc-pub.org/articles/abstract/10.7710/2162-3309.2235/},
	doi = {10.7710/2162-3309.2235},
	abstract = {The Journal of Librarianship and Scholarly Communication seeks to share useful innovations, both in thought and in practice, with the aim of encouraging scholarly exchange and the subsequent benefits that are borne of scrutiny, experimentation and debate. As modes of scholarly communication, the technologies and economics of publishing and the roles of libraries evolve, it is our hope that the work shared in the journal will inform practices that strengthen librarianship and that increase access to the "common Stock of Knowledge."JLSC is particularly interested in the intersection of librarianship and publishing and the resulting role of libraries in both content dissemination and content creation. Related areas of interest include new methods for the dissemination of information and information exchange; the theory and practice of the organization, use and curation of information; and issues related to the review, credentialing, reputation and impact of scholarly work.},
	language = {eng},
	number = {2},
	urldate = {2021-03-25},
	journal = {Journal of Librarianship and Scholarly Communication},
	author = {Wheeler, Jonathan},
	month = aug,
	year = {2018},
	note = {Number: 2
Publisher: Pacific University Libraries},
	pages = {eP2235},
}

@article{maieretal2018,
	title = {Applying {LDA} {Topic} {Modeling} in {Communication} {Research}: {Toward} a {Valid} and {Reliable} {Methodology}},
	volume = {12},
	issn = {1931-2458},
	shorttitle = {Applying {LDA} {Topic} {Modeling} in {Communication} {Research}},
	url = {https://doi.org/10.1080/19312458.2018.1430754},
	doi = {10.1080/19312458.2018.1430754},
	abstract = {Latent Dirichlet allocation (LDA) topic models are increasingly being used in communication research. Yet, questions regarding reliability and validity of the approach have received little attention thus far. In applying LDA to textual data, researchers need to tackle at least four major challenges that affect these criteria: (a) appropriate pre-processing of the text collection; (b) adequate selection of model parameters, including the number of topics to be generated; (c) evaluation of the model’s reliability; and (d) the process of validly interpreting the resulting topics. We review the research literature dealing with these questions and propose a methodology that approaches these challenges. Our overall goal is to make LDA topic modeling more accessible to communication researchers and to ensure compliance with disciplinary standards. Consequently, we develop a brief hands-on user guide for applying LDA topic modeling. We demonstrate the value of our approach with empirical data from an ongoing research project.},
	number = {2-3},
	urldate = {2021-03-25},
	journal = {Communication Methods and Measures},
	author = {Maier, Daniel and Waldherr, A. and Miltner, P. and Wiedemann, G. and Niekler, A. and Keinert, A. and Pfetsch, B. and Heyer, G. and Reber, U. and Häussler, T. and Schmid-Petri, H. and Adam, S.},
	year = {2018},
	note = {Publisher: Routledge
\_eprint: https://doi.org/10.1080/19312458.2018.1430754},
	pages = {93--118},
}

@article{atteveldtpeng2018,
	title = {When {Communication} {Meets} {Computation}: {Opportunities}, {Challenges}, and {Pitfalls} in {Computational} {Communication} {Science}},
	volume = {12},
	issn = {1931-2458},
	shorttitle = {When {Communication} {Meets} {Computation}},
	url = {https://doi.org/10.1080/19312458.2018.1458084},
	doi = {10.1080/19312458.2018.1458084},
	abstract = {The recent increase in digitally available data, tools, and processing power is fostering the use of computational methods to the study of communication. This special issue discusses the validity of using big data in communication science and showcases a number of new methods and applications in the fields of text and network analysis. Computational methods have the potential to greatly enhance the scientific study of communication because they allow us to move towards collaborative large-N studies of actual behavior in its social context. This requires us to develop new skills and infrastructure and meet the challenges of open, valid, reliable, and ethical “big data” research. By bringing together a number of leading scholars in one issue, we contribute to the increasing development and adaptation of computational methods in communication science.},
	number = {2-3},
	urldate = {2021-03-25},
	journal = {Communication Methods and Measures},
	author = {Atteveldt, Wouter van and Peng, Tai-Quan},
	year = {2018},
	note = {Publisher: Routledge
\_eprint: https://doi.org/10.1080/19312458.2018.1458084},
	pages = {81--92},
}

@article{bulamah2020,
	title = {Times and metaphors of pandemics},
	journal = {Social Anthropology},
	author = {Bulamah, Rodrigo Charafeddine},
	year = {2020},
	note = {Publisher: Wiley-Blackwell},
}

@article{craig2020,
	title = {Pandemic and its metaphors: {Sontag} revisited in the {COVID}-19 era},
	volume = {23},
	shorttitle = {Pandemic and its metaphors},
	number = {6},
	journal = {European Journal of Cultural Studies},
	author = {Craig, David},
	year = {2020},
	note = {Publisher: SAGE Publications Sage UK: London, England},
	pages = {1025--1032},
}

@inproceedings{jorke_attending_2020,
	address = {Online},
	title = {Attending to {Long}-{Distance} {Document} {Context} for {Sequence} {Labeling}},
	url = {https://www.aclweb.org/anthology/2020.findings-emnlp.330},
	doi = {10.18653/v1/2020.findings-emnlp.330},
	abstract = {We present in this work a method for incorporating global context in long documents when making local decisions in sequence labeling problems like NER. Inspired by work in featurized log-linear models (Chieu and Ng, 2002; Sutton and McCallum, 2004), our model learns to attend to multiple mentions of the same word type in generating a representation for each token in context, extending that work to learning representations that can be incorporated into modern neural models. Attending to broader context at test time provides complementary information to pretraining (Gururangan et al., 2020), yields strong gains over equivalently parameterized models lacking such context, and performs best at recognizing entities with high TF-IDF scores (i.e., those that are important within a document).},
	language = {en},
	urldate = {2021-03-13},
	booktitle = {Findings of the {Association} for {Computational} {Linguistics}: {EMNLP} 2020},
	publisher = {Association for Computational Linguistics},
	author = {Jörke, Matthew and Gillick, Jon and Sims, Matthew and Bamman, David},
	year = {2020},
	pages = {3692--3704},
}

@inproceedings{fevryetal2020,
	address = {Online},
	title = {Entities as {Experts}: {Sparse} {Memory} {Access} with {Entity} {Supervision}},
	shorttitle = {Entities as {Experts}},
	url = {https://www.aclweb.org/anthology/2020.emnlp-main.400},
	doi = {10.18653/v1/2020.emnlp-main.400},
	abstract = {We focus on the problem of capturing declarative knowledge about entities in the learned parameters of a language model. We introduce a new model—Entities as Experts (EAE)—that can access distinct memories of the entities mentioned in a piece of text. Unlike previous efforts to integrate entity knowledge into sequence models, EAE’s entity representations are learned directly from text. We show that EAE’s learned representations capture sufﬁcient knowledge to answer TriviaQA questions such as “Which Dr. Who villain has been played by Roger Delgado, Anthony Ainley, Eric Roberts?”, outperforming an encodergenerator Transformer model with 10× the parameters. According to the LAMA knowledge probes, EAE contains more factual knowledge than a similarly sized BERT, as well as previous approaches that integrate external sources of entity knowledge. Because EAE associates parameters with speciﬁc entities, it only needs to access a fraction of its parameters at inference time, and we show that the correct identiﬁcation and representation of entities is essential to EAE’s performance.},
	language = {en},
	urldate = {2021-03-13},
	booktitle = {Proceedings of the 2020 {Conference} on {Empirical} {Methods} in {Natural} {Language} {Processing} ({EMNLP})},
	publisher = {Association for Computational Linguistics},
	author = {Févry, Thibault and Baldini Soares, Livio and FitzGerald, Nicholas and Choi, Eunsol and Kwiatkowski, Tom},
	year = {2020},
	pages = {4937--4951},
}

@article{liuetal2021,
	title = {Understanding the onset of hot streaks across artistic, cultural, and scientific careers},
	url = {http://arxiv.org/abs/2103.01256},
	abstract = {Hot streaks dominate the main impact of creative careers. Despite their ubiquitous nature across a wide range of creative domains, it remains unclear if there is any regularity underlying the beginning of hot streaks. Here, we develop computational methods using deep learning and network science and apply them to novel, large-scale datasets tracing the career outputs of artists, film directors, and scientists, allowing us to build high-dimensional representations of the artworks, films, and scientific publications they produce. By examining individuals' career trajectories within the underlying creative space, we find that across all three domains, individuals tend to explore diverse styles or topics before their hot streak, but become notably more focused in what they work on after the hot streak begins. Crucially, we find that hot streaks are associated with neither exploration nor exploitation behavior in isolation, but a particular sequence of exploration followed by exploitation, where the transition from exploration to exploitation closely traces the onset of a hot streak. Overall, these results unveil among the first identifiable regularity underlying the onset of hot streaks, which appears universal across diverse creative domains, suggesting that a sequential view of creative strategies that balances experimentation and implementation may be particularly powerful for producing long-lasting contributions, which may have broad implications for identifying and nurturing creative talents.},
	urldate = {2021-03-04},
	journal = {arXiv:2103.01256 [physics]},
	author = {Liu, Lu and Dehmamy, Nima and Chown, Jillian and Giles, C. Lee and Wang, Dashun},
	year = {2021},
	note = {arXiv: 2103.01256},
	keywords = {Physics - Physics and Society},
}

@article{waisanenkafka2020,
	title = {Conflicting purposes in {U}.{S}. education reform: {The} paradoxes of {Arne} {Duncan}'s educational rhetoric},
	volume = {23},
	journal = {Rhetoric \& Public Affairs},
	author = {Waisanen, Don J. and Kafka, Judith},
	year = {2020},
}

@article{schwartzmanetal2011,
	title = {Rhetoric and risk},
	volume = {7},
	issn = {2151-2957},
	url = {https://ir.uiowa.edu/poroi/vol7/iss1/9},
	doi = {10.13008/2151-2957.1087},
	language = {en},
	number = {1},
	urldate = {2020-07-24},
	journal = {Poroi},
	author = {Schwartzman, Roy and Ross, Derek G. and Berube, David M.},
	year = {2011},
}

@book{ridolfohart-davidson2015,
	title = {Rhetoric and the digital humanities},
	isbn = {978-0-226-17669-7},
	abstract = {The digital humanities is a rapidly growing field that is transforming humanities research through digital tools and resources. Researchers can now quickly trace every one of Issac Newton’s annotations, use social media to engage academic and public audiences in the interpretation of cultural texts, and visualize travel via ox cart in third-century Rome or camel caravan in ancient Egypt. Rhetorical scholars are leading the revolution by fully utilizing the digital toolbox, finding themselves at the nexus of digital innovation.  Rhetoric and the Digital Humanities is a timely, multidisciplinary collection that is the first to bridge scholarship in rhetorical studies and the digital humanities. It offers much-needed guidance on how the theories and methodologies of rhetorical studies can enhance all work in digital humanities, and vice versa. Twenty-three essays over three sections delve into connections, research methodology, and future directions in this field. Jim Ridolfo and William Hart-Davidson have assembled a broad group of more than thirty accomplished scholars. Read together, these essays represent the cutting edge of research, offering guidance that will energize and inspire future collaborations.},
	language = {en},
	publisher = {University of Chicago Press},
	author = {Ridolfo, Jim and Hart-Davidson, William},
	year = {2015},
	note = {Google-Books-ID: 64MLBgAAQBAJ},
	keywords = {Language Arts \& Disciplines / Library \& Information Science / Digital \& Online Resources, Language Arts \& Disciplines / Rhetoric, Literary Criticism / General},
}

@incollection{rapp2010,
	edition = {Spring 2010},
	title = {Aristotle's {Rhetoric}},
	url = {https://plato.stanford.edu/archives/spr2010/entries/aristotle-rhetoric/},
	abstract = {Aristotle's Rhetoric has had an enormous influence on the development of the art of rhetoric. Not only authors writing in the peripatetic tradition, but also the famous Roman teachers of rhetoric, such as Cicero and Quintilian, frequently used elements stemming from the Aristotelian doctrine. Nevertheless, these authors were interested neither in an authentic interpretation of the Aristotelian works nor in the philosophical sources and backgrounds of the vocabulary that Aristotle had introduced to rhetorical theory.Thus, for two millennia the interpretation of Aristotelian rhetoric has become a matter of the history of rhetoric, not of philosophy. Inthe most influential manuscripts and editions, Aristotle's Rhetoric was surrounded by rhetorical works and even writtenspeeches of other Greek and Latin authors, and was seldom interpretedin the context of the whole Corpus Aristotelicum. It was not until the last few decades that the philosophically salient features of theAristotelian rhetoric were rediscovered: in construing a general theory of the persuasive, Aristotle applies numerous concepts and arguments that are also treated in his logical, ethical, and psychological writings. His theory of rhetorical arguments, for example, is only one further application of his general doctrine of the sullogismos, which also forms the basis of dialectic, logic, and his theory of demonstration. Another example is the concept of emotions: though emotions are one of the most important topics in the Aristotelian ethics, he nowhere offers such an illuminating account of single emotions as in the Rhetoric. Finally, it is the Rhetoric, too, that informs us about the cognitive features of language and style.},
	urldate = {2020-07-27},
	booktitle = {The {Stanford} {Encyclopedia} of {Philosophy}},
	publisher = {Metaphysics Research Lab, Stanford University},
	author = {Rapp, Christof},
	editor = {Zalta, Edward N.},
	year = {2010},
	keywords = {Aristotle, Aristotle, General Topics: logic, Cicero, Plato: rhetoric and poetry},
}

@article{mccloskey1983,
	title = {The rhetoric of economics},
	volume = {21},
	issn = {0022-0515},
	url = {https://www.jstor.org/stable/2724987},
	number = {2},
	urldate = {2020-07-27},
	journal = {Journal of Economic Literature},
	author = {McCloskey, Donald N.},
	year = {1983},
	pages = {481--517},
}

@article{huckinetal2012,
	title = {Critical {Discourse} {Analysis} and {Rhetoric} and {Composition}},
	volume = {64},
	language = {en},
	number = {1},
	journal = {College Composition and Communication},
	author = {Huckin, Thomas and Andrus, Jennifer and Clary-Lemon, Jennifer},
	year = {2012},
	pages = {107--129},
}

@book{hauser2002,
	edition = {2nd},
	title = {Introduction to rhetorical theory},
	isbn = {978-1-4786-0894-3},
	shorttitle = {Introduction to rhetorical theory},
	abstract = {In this highly accessible new edition, Hauser systematically provides a humanistic account of what transpires when people communicate for some purpose. His masterful blend of classical and contemporary thinking about the use of language and the value of symbolic inducements for social cooperation illuminates fundamental rhetorical precepts and their implications for shaping human realities. The new chapter on publics theory complements the four chapters that introduce the broad themes and issues essential for a rhetorical approach to communication. The new chapter on narrative theory bridges the four chapters devoted to the content of rhetoric and the concluding chapters that emphasize symbolic processes by which humans induce social cooperation and constitute social reality. Throughout the text, Hauser skillfully underscores the power of language to present a particular reality. He explores the fundamental relationship between public discourse and judgment, helping students understand the core of rhetorics civic function. Through relevant, current examples, he illustrates how knowledge and power shape our social and political practices and how both are formed through discourse.},
	language = {en},
	publisher = {Waveland Press},
	author = {Hauser, Gerard A.},
	year = {2002},
	keywords = {Language Arts \& Disciplines / Communication Studies, Language Arts \& Disciplines / Rhetoric},
}

@article{harrisetal2017,
	title = {A cognitive ontology of rhetorical figures},
	journal = {Cognition and Ontologies},
	author = {Harris, Randy Allen and Di Marco, Chrysanne and Mehlenbacher, Ashley Rose and Clapperton, Robert and Choi, Insun and Li, Isabel and Ruan, Sebastian and O’Reilly, Cliff},
	year = {2017},
	pages = {18--21},
}

@article{harrisdimarco2017,
	title = {Rhetorical figures, arguments, computation},
	volume = {8},
	number = {3},
	journal = {Argument \& Computation},
	author = {Harris, Randy Allen and Di Marco, Chrysanne},
	year = {2017},
	note = {Publisher: IOS Press},
	pages = {211--231},
}

@article{hariman1986,
	title = {Status, marginality, and rhetorical theory},
	volume = {72},
	issn = {0033-5630, 1479-5779},
	url = {http://www.tandfonline.com/doi/abs/10.1080/00335638609383757},
	doi = {10.1080/00335638609383757},
	language = {en},
	number = {1},
	urldate = {2020-07-22},
	journal = {Quarterly Journal of Speech},
	author = {Hariman, Robert},
	year = {1986},
	pages = {38--54},
}

@article{grayholmes2020,
	title = {Tracing ecologies of code literacy and constraint in emojis as multimodal public pedagogy},
	volume = {55},
	issn = {8755-4615},
	url = {http://www.sciencedirect.com/science/article/pii/S875546152030013X},
	doi = {10.1016/j.compcom.2020.102552},
	abstract = {This article explores the role of Bitzer's constraint through Brooke's ecologies of code, culture, and practice as a method to analyze emoji as a form of multimodal public rhetoric. In particular, this article suggests that understanding digital forms such as emoji, which are controlled by the Unicode consortium, requires understanding the essential role that code literacy can play in shaping public writing practices in social media through two case studies: one on the multicultural skin tone emoji iOS update of 2015 and another on public emoji proposals as a way to illustrate how everyday rhetors can use networked writing intervene at the level of code.},
	language = {en},
	urldate = {2020-02-04},
	journal = {Computers and Composition},
	author = {Gray, Kellie and Holmes, Steve},
	year = {2020},
	keywords = {code, constraint, ecology, emoji, multimodal public writing},
	pages = {102552},
}

@book{gray2019,
	title = {The grammatical foundations of rhetoric: {Discourse} analysis},
	isbn = {978-3-11-080484-3},
	shorttitle = {The grammatical foundations of rhetoric},
	language = {en},
	publisher = {Walter de Gruyter GmbH \& Co KG},
	author = {Gray, Bennison},
	year = {2019},
	note = {Google-Books-ID: E\_ygDwAAQBAJ},
	keywords = {Language Arts \& Disciplines / Linguistics / General, Language Arts \& Disciplines / Linguistics / Historical \& Comparative},
}

@article{goodnight2010,
	title = {The metapolitics of the 2002 {Iraq} debate: {Public} policy and the network imaginary},
	volume = {13},
	issn = {1534-5238},
	shorttitle = {The metapolitics of the 2002 iraq debate},
	url = {http://muse.jhu.edu/content/crossref/journals/rhetoric_and_public_affairs/v013/13.1.goodnight.html},
	doi = {10.1353/rap.0.0132},
	language = {en},
	number = {1},
	urldate = {2020-01-09},
	journal = {Rhetoric \& Public Affairs},
	author = {Goodnight, G. Thomas},
	year = {2010},
	pages = {65--94},
}

@book{farrell1995,
	title = {Norms of rhetorical culture},
	isbn = {978-0-300-06502-2},
	abstract = {Rhetoric is widely regarded by both its detractors and advocates as a kind of antithesis to reason. In this book Thomas B. Farrell restores rhetoric as an art of practical reason and enlightened civic participation, grounding it in its classical tradition--particularly in the rhetoric of Aristotle. And, because prevailing modernist world views bear principal responsibility for the disparagement of rhetorical tradition, Farrell also offers a critique of the dominant currents of modern humanist thought.  Farrell argues that rhetoric is not antithetical to reason but is a manner of posing and answering questions that is distinct from the approaches of analytic and dialectical reason. He develops this position in a number of ways: through a series of bold reinterpretations of Aristotle's Rhetoric; through a detailed appraisal of traditional rhetorical concepts as seen in modern texts from the Army-McCarthy hearings to Edward Kennedy's memorial for his brother, Mario Cuomo's address on abortion, Betty Friedan's Feminine Mystique, and Vaclav Havel's inaugural address; and through a fresh appraisal of theories on the character of language and discourse found in contemporary philosophy, literary criticism, anthropology, deconstructionism, Marxism, and especially in Habermas's critical theory of communicative action.},
	language = {en},
	publisher = {Yale University Press},
	author = {Farrell, Thomas B.},
	year = {1995},
	keywords = {Philosophy / Methodology},
}

@misc{montanez2016,
	title = {Unveiling the hidden layers of deep learning},
	url = {https://blogs.scientificamerican.com/sa-visual/unveiling-the-hidden-layers-of-deep-learning/},
	abstract = {Interactive neural network "playground" visualization offers insights on how machines learn},
	language = {en},
	journal = {Scientific American Blog Network},
	author = {Montañez, Amanda},
	year = {2016},
}

@article{panaggioetal2021,
	title = {Can subjective pain be inferred from objective physiological data? {Evidence} from patients with sickle cell disease},
	volume = {17},
	issn = {1553-7358},
	shorttitle = {Can subjective pain be inferred from objective physiological data?},
	url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1008542},
	doi = {10.1371/journal.pcbi.1008542},
	abstract = {Patients with sickle cell disease (SCD) experience lifelong struggles with both chronic and acute pain, often requiring medical interventMaion. Pain can be managed with medications, but dosages must balance the goal of pain mitigation against the risks of tolerance, addiction and other adverse effects. Setting appropriate dosages requires knowledge of a patient’s subjective pain, but collecting pain reports from patients can be difficult for clinicians and disruptive for patients, and is only possible when patients are awake and communicative. Here we investigate methods for estimating SCD patients’ pain levels indirectly using vital signs that are routinely collected and documented in medical records. Using machine learning, we develop both sequential and non-sequential probabilistic models that can be used to infer pain levels or changes in pain from sequences of these physiological measures. We demonstrate that these models outperform null models and that objective physiological data can be used to inform estimates for subjective pain.},
	language = {en},
	number = {3},
	urldate = {2021-03-13},
	journal = {PLOS Computational Biology},
	author = {Panaggio, Mark J. and Abrams, Daniel M. and Yang, Fan and Banerjee, Tanvi and Shah, Nirmish R.},
	year = {2021},
	note = {Publisher: Public Library of Science},
	keywords = {Evolutionary physiology, Forecasting, Heart rate, Hidden Markov models, Mathematical models, Pain, Probability distribution, Sickle cell disease},
	pages = {e1008542},
}

@article{semino2021,
	title = {"{Not} {Soldiers} but {Fire}-fighters"–{Metaphors} and {Covid}-19},
	volume = {36},
	number = {1},
	journal = {Health Communication},
	author = {Semino, Elena},
	year = {2021},
	note = {Publisher: Taylor \& Francis},
	pages = {50--58},
}

@article{pickering1993,
	title = {The mangle of practice: {Agency} and emergence in the sociology of science},
	volume = {99},
	shorttitle = {The mangle of practice},
	number = {3},
	journal = {American Journal of Sociology},
	author = {Pickering, Andrew},
	year = {1993},
	pages = {559--589},
}

@article{majdik2019,
	title = {A computational approach to assessing rhetorical effectiveness: {Agentic} framing of climate change in the {Congressional} {Record}, 1994–2016},
	volume = {28},
	copyright = {All rights reserved},
	issn = {1057-2252},
	shorttitle = {A computational approach to assessing rhetorical effectiveness},
	url = {https://doi.org/10.1080/10572252.2019.1601774},
	doi = {10.1080/10572252.2019.1601774},
	abstract = {The goal of this paper is to consider rhetorical effects as the propagation of rhetorical expressions across large sets of texts, measured by the extent to which rhetorical expressions, structures, or practices become replicated in texts and sites of rhetorical in(ter)vention. The paper draws on lines of scholarship in the digital humanities and computational rhetoric – primarily, sequential structuring of semantic contexts, semantic parsing of unstructured text, and diachronic tracking of textual expressions – to extend their conceptual and methodological insights into a computational framework for assessing rhetorical effectiveness. It offers a test case for this concept through an analysis of how Congress has framed human agency toward addressing climate change.},
	number = {3},
	journal = {Technical Communication Quarterly},
	author = {Majdik, Zoltan P.},
	year = {2019},
	keywords = {Climate change, computational rhetoric, digital humanities, rhetorical effects},
	pages = {207--222},
}

@article{grahametal2020a,
	title = {Methods for {Extracting} {Relational} {Data} from {Unstructured} {Texts} {Prior} to {Network} {Visualization} in {Humanities} {Research}},
	volume = {6},
	copyright = {All rights reserved},
	url = {https://openhumanitiesdata.metajnl.com/articles/10.5334/johd.21/},
	doi = {10.5334/johd.21},
	number = {8},
	journal = {Journal of Open Humanities Data},
	author = {Graham, S. Scott and {Majdik, Zoltan P.} and {Clark, Dave}},
	year = {2020},
}

@article{taylor2010,
	title = {Science in the news: a diachronic perspective},
	volume = {5},
	issn = {1749-5032},
	shorttitle = {Science in the news},
	url = {https://www.euppublishing.com/doi/abs/10.3366/cor.2010.0106},
	doi = {10.3366/cor.2010.0106},
	abstract = {In this paper, I analyse the changing rhetorical role of science in UK broadsheet newspapers from 1993 and 2005, and conclude that there have been noteworthy changes. First, science, and more speci...},
	number = {2},
	urldate = {2020-07-24},
	journal = {Corpora},
	author = {Taylor, Charlotte},
	month = nov,
	year = {2010},
	note = {Publisher: Edinburgh University Press},
	pages = {221--250},
}

@article{sullivan2013,
	title = {A call for reaffirming a humanist understanding of technology},
	volume = {5},
	language = {en},
	number = {1},
	journal = {Programmatic Perspectives},
	author = {Sullivan, Dale L},
	year = {2013},
	pages = {153--157},
}

@article{simisetal2016,
	title = {The lure of rationality: {Why} does the deficit model persist in science communication?:},
	shorttitle = {The lure of rationality},
	url = {https://journals.sagepub.com/doi/10.1177/0963662516629749},
	doi = {10.1177/0963662516629749},
	abstract = {Science communication has been historically predicated on the knowledge deficit model. Yet, empirical research has shown that public communication of science is...},
	language = {en},
	urldate = {2020-01-27},
	journal = {Public Understanding of Science},
	author = {Simis, Molly J. and Madden, Haley and Cacciatore, Michael A. and Yeo, Sara K.},
	month = apr,
	year = {2016},
}

@book{simonnaesetal2019,
	title = {New challenges for research on language for special purposes},
	isbn = {978-3-7329-0420-4},
	abstract = {This anthology consists of selected papers presented by European  scholars at the 21st LSP-Conference 2017 on Interdisciplinary  knowledge-making: challenges for LSP-research, held at NHH Norwegian  School of Economics in Bergen, Norway. The multifarious aspects of  LSP-research publication cover issues on terms and terminology,  LSP-texts from a text linguistic approach, training in LSP-settings and  translation of LSPtexts. The volume gives an up-to-date selection of the  ongoing research endeavours in specialised communication in subject  fields ranging from maritime accidents over healthcare and financial  accounting to climate change.},
	language = {en},
	publisher = {Frank \& Timme GmbH},
	author = {Simonnæs, Ingrid and Andersen, Øivin and Schubert, Klaus},
	year = {2019},
	note = {Google-Books-ID: JtisDwAAQBAJ},
}

@article{bitzer1992,
	title = {The rhetorical situation},
	journal = {Philosophy \& rhetoric},
	author = {Bitzer, Lloyd F.},
	year = {1992},
	note = {Publisher: JSTOR},
	pages = {1--14},
}

@book{bieseckerlucaites2009,
	title = {Rhetoric, materiality, \& politics},
	isbn = {978-0-8204-9740-2},
	abstract = {Rhetoric, Materiality, and Politics explores the relationship between rhetoric's materiality and the social world in the late modern political context. Taking as their point of departure a reprint of Michael Calvin McGee's 1982 call to reconceptualize rhetoric as the palpable «experience» of sociality, the authors in this volume grapple anew with the role of communication practices in contemporary collective life. Drawing upon the work of Michel Foucault, Jacques Lacan, and Jacques Derrida, these twelve original essays supplement, extend, and challenge McGee's position, collectively advocating on behalf of a shift in theoretical and critical attention from rhetorical materialism to rhetoric's materiality.},
	language = {en},
	publisher = {Peter Lang},
	author = {Biesecker, Barbara A. and Lucaites, John Louis},
	year = {2009},
	note = {Google-Books-ID: 9sDYtnTB7LYC},
	keywords = {Language Arts \& Disciplines / Rhetoric, Political Science / Essays},
}

@book{aristotle2006,
	address = {Cambridge, MA},
	title = {The "art" of rhetoric},
	publisher = {Harvard University Press},
	author = {Aristotle},
	year = {2006},
}

@article{barnaghietal2013,
	title = {From data to actionable knowledge: {Big} data challenges in the web of things},
	volume = {28},
	issn = {1941-1294},
	shorttitle = {From data to actionable knowledge},
	doi = {10.1109/MIS.2013.142},
	abstract = {Extending the current Internet and providing connection, communication, and internetworking between devices and physical objects, or "things," is a growing trend that's often referred to as the Internet of Things (IoT). Integrating real-world data into the Web, with its large repositories of data, and providing Web-based interactions between humans and IoT resources is what the Web of Things (WoT) stands for. Here, the guest editors describe the Big Data issues in the WoT, discuss the challenges of extracting actionable knowledge and insights from raw sensor data, and introduce the theme articles in this special issue.},
	number = {6},
	journal = {IEEE Intelligent Systems},
	author = {Barnaghi, Payam and Sheth, Amit and Henson, Cory},
	year = {2013},
	note = {Conference Name: IEEE Intelligent Systems},
	keywords = {Big Data, Internet of Things, IoT, Knowledge management, Special issues and sections, Web and internet services, Web of Things, WoT, intelligent systems, internetworking},
	pages = {6--11},
}

@misc{berkeleyschoolofinformation2019,
	title = {Big data isn’t a concept — it’s a problem to solve},
	url = {https://datascience.berkeley.edu/blog/what-is-big-data/},
	abstract = {What is big data? To some it represents a cultural shift and for others it’s simply a concept. Here we deconstruct the term “big data,” and discuss how we should talk about it and what it sets us up to do for the future with AnnaLee Saxenian, dean of the UC Berkeley School of Information (I School).},
	language = {en},
	urldate = {2020-07-21},
	author = {{Berkeley School of Information}},
	year = {2019},
	note = {Library Catalog: datascience.berkeley.edu},
}

@article{bennett2015,
	title = {Found in translation: {Combining} discourse analysis with computer assisted content analysis},
	volume = {43},
	issn = {0305-8298},
	shorttitle = {Found in translation},
	url = {https://doi.org/10.1177/0305829815581535},
	doi = {10.1177/0305829815581535},
	abstract = {Scholars have become increasingly aware of the benefits of multi-method research, through which the strengths of one method can offset the limits of another. Yet epistemological differences between interpretivists and researchers interested in quantitative methods and causal explanation have inhibited a potentially fruitful multi-method approach: combining discourse analysis and computer-assisted content analysis. The growing availability of digital text is creating new opportunities for combining these methods, so if scholars treat their epistemological assumptions as reconcilable and translatable epistemic wagers rather than incompatible commitments, there is much to be gained. Computer-assisted searches can quickly identify patterns in vast amounts of text and provide clues on which particular texts (and silences) merit a close reading and interpretation in context, and scholars versed in discourse analysis are adept at making such interpretations. Researchers from these two communities, who at present rarely cite one another’s work, have much to learn from each other, and much to gain by working together.},
	language = {en},
	number = {3},
	urldate = {2020-01-10},
	journal = {Millennium},
	author = {Bennett, Andrew},
	month = jun,
	year = {2015},
	keywords = {computer assisted content analysis, discourse analysis, methodology},
	pages = {984--997},
}

@article{allenbyetal2014,
	title = {Perspectives on {Bayesian} methods and big data},
	volume = {1},
	number = {3},
	journal = {Customer Needs and Solutions},
	author = {Allenby, Greg M. and Bradlow, Eric T. and George, Edward I. and Liechty, John and McCulloch, Robert E.},
	year = {2014},
	note = {Publisher: Springer},
	pages = {169--175},
}

@article{burke_four_1941,
	title = {Four {Master} {Tropes}},
	volume = {3},
	issn = {0163-075X},
	url = {https://www.jstor.org/stable/4332286},
	number = {4},
	urldate = {2021-02-22},
	journal = {The Kenyon Review},
	author = {Burke, Kenneth},
	year = {1941},
	note = {Publisher: Kenyon College},
	pages = {421--438},
}

@inproceedings{ouyang_modeling_2015,
	address = {Lisbon, Portugal},
	title = {Modeling {Reportable} {Events} as {Turning} {Points} in {Narrative}},
	url = {http://aclweb.org/anthology/D15-1257},
	doi = {10.18653/v1/D15-1257},
	abstract = {We present novel experiments in modeling the rise and fall of story characteristics within narrative, leading up to the Most Reportable Event (MRE), the compelling event that is the nucleus of the story. We construct a corpus of personal narratives from the bulletin board website Reddit, using the organization of Reddit content into topic-speciﬁc communities to automatically identify narratives. Leveraging the structure of Reddit comment threads, we automatically label a large dataset of narratives. We present a change-based model of narrative that tracks changes in formality, affect, and other characteristics over the course of a story, and we use this model in distant supervision and selftraining experiments that achieve signiﬁcant improvements over the baselines at the task of identifying MREs.},
	language = {en},
	urldate = {2021-02-17},
	booktitle = {Proceedings of the 2015 {Conference} on {Empirical} {Methods} in {Natural} {Language} {Processing}},
	publisher = {Association for Computational Linguistics},
	author = {Ouyang, Jessica and McKeown, Kathleen},
	year = {2015},
	pages = {2149--2158},
}

@article{majdik2021,
	title = {Five {Considerations} for {Engaging} {With} {Big} {Data} {From} a {Rhetorical}-{Humanistic} {Perspective}},
	volume = {16},
	copyright = {All rights reserved},
	number = {1},
	journal = {Poroi},
	author = {Majdik, Zoltan P.},
	year = {2021},
}

@article{grasso2002,
	title = {Towards computational rhetoric},
	volume = {22},
	copyright = {Copyright (c) 2014 Informal Logic},
	url = {https://informallogic.ca/index.php/informal_logic/article/view/2589},
	doi = {10.22329/il.v22i3.2589},
	abstract = {The notions of argument and argumentation have become increasingly ubiquitous in Artificial Intelligence research, with various application and interpretations. Less attention has been, however, specifically devoted to rhetorical argument The
work presented in this paper aims at bridging this gap, by proposing a framework for characterising rhetorical argumentation, based on Perelman and Olbrechts-Tyteca's New Rhetoric. The paper provides an overview of the state of the art of computational work based on, or dealing with, rhetorical
aspects of argumentation, before presenting the characterisation proposed, corroborated by walked-through examples.},
	number = {3},
	urldate = {2020-03-27},
	journal = {Informal Logic},
	author = {Grasso, Floriana},
	year = {2002},
	note = {Number: 3},
	keywords = {Artificial Agents, Computational Linguistics, New Rhetoric},
}

@article{grahametal2020,
	title = {Relationships among commercial practices and author conflicts of interest in biomedical publishing},
	volume = {15},
	copyright = {All rights reserved},
	doi = {https://doi.org/10.1371/journal.pone.0236166},
	number = {7},
	journal = {PLOS One},
	author = {Graham, S. Scott and Majdik, Zoltan P. and Clark, Dave and Kessler, Molly M. and Hooker, Tristin Brynn},
	year = {2020},
	note = {Publisher: Public Library of Science San Francisco, CA USA},
}

@book{piper_can_2020,
	title = {Can {We} {Be} {Wrong}? {The} {Problem} of {Textual} {Evidence} in a {Time} of {Data}},
	shorttitle = {Can {We} {Be} {Wrong}?},
	publisher = {Cambridge University Press},
	author = {Piper, Andrew},
	year = {2020},
}

@article{rahman_social_2020,
	title = {‘{Social} distancing’during {COVID}-19: the metaphors and politics of pandemic response in {India}},
	volume = {29},
	shorttitle = {‘{Social} distancing’during {COVID}-19},
	number = {2},
	journal = {Health Sociology Review},
	author = {Rahman, Sabina Yasmin},
	year = {2020},
	note = {Publisher: Taylor \& Francis},
	pages = {131--139},
}

@article{rajandran_long_2020,
	title = {‘{A} {Long} {Battle} {Ahead}’: {Malaysian} and {Singaporean} {Prime} {Ministers} {Employ} {War} {Metaphors} for {COVID}-19},
	volume = {20},
	shorttitle = {‘{A} {Long} {Battle} {Ahead}’},
	number = {3},
	journal = {GEMA Online® Journal of Language Studies},
	author = {Rajandran, Kumaran},
	year = {2020},
}

@article{brencio2020,
	title = {Mind your words. {Language} and war metaphors in the {COVID}-19 pandemic},
	volume = {9},
	number = {2},
	journal = {Revista Psicopatologia Fenomenológica Contemporânea},
	author = {Brencio, Francesca},
	year = {2020},
	pages = {58--73},
}

@book{marron_waging_2020,
	title = {Waging war on war metaphors in cancer and {COVID}-19},
	publisher = {American Society of Clinical Oncology},
	author = {Marron, Jonathan M. and Dizon, Don S. and Symington, Banu and Thompson, Michael A. and Rosenberg, Abby R.},
	year = {2020},
}

@article{geoghegan_information_2011,
	title = {From information theory to {French} theory: {Jakobson}, {Lévi}-{Strauss}, and the cybernetic apparatus},
	volume = {38},
	issn = {0093-1896, 1539-7858},
	shorttitle = {From {Information} {Theory} to {French} {Theory}},
	url = {https://www.journals.uchicago.edu/doi/10.1086/661645},
	doi = {10.1086/661645},
	language = {en},
	number = {1},
	urldate = {2020-08-17},
	journal = {Critical Inquiry},
	author = {Geoghegan, Bernard Dionysius},
	month = sep,
	year = {2011},
	pages = {96--126},
}

@article{edwardsetal2016,
	title = {Countering vaccine hesitancy},
	volume = {138},
	issn = {0031-4005, 1098-4275},
	url = {http://pediatrics.aappublications.org/cgi/doi/10.1542/peds.2016-2146},
	doi = {10.1542/peds.2016-2146},
	abstract = {This document is copyrighted and is property of the American Academy of Pediatrics and its Board of Directors. All authors have ﬁled conﬂict of interest statements with the American Academy of Pediatrics. Any conﬂicts have been resolved through a process approved by the Board of Directors. The American Academy of Pediatrics has neither solicited nor accepted any commercial involvement in the development of the content of this publication.},
	language = {en},
	number = {3},
	urldate = {2020-01-17},
	journal = {PEDIATRICS},
	author = {Edwards, K. M. and Hackell, J. M. and {THE COMMITTEE ON INFECTIOUS DISEASES, THE COMMITTEE ON PRACTICE AND AMBULATORY MEDICINE}},
	month = sep,
	year = {2016},
	pages = {e20162146--e20162146},
}

@article{charland1987,
	title = {Constitutive rhetoric: {The} case of the peuple québécois},
	volume = {73},
	issn = {00335630},
	shorttitle = {Constitutive rhetoric},
	url = {https://ezproxy.lib.ndsu.nodak.edu/login?url=https://search.ebscohost.com/login.aspx?direct=true&db=ufh&AN=10104146&site=ehost-live&scope=site},
	doi = {10.1080/00335638709383799},
	abstract = {Focuses on the constitutive rhetoric regarding the sovereignty of Quebec province.  Development of political associations dedicated to Quebec's political sovereignty; Appraisal of the narrative ideological effect of rhetoric; Assessment of the effective power of constitutive rhetoric; Overview of a white paper drafted to secure Quebec's sovereignty.},
	number = {2},
	urldate = {2020-07-25},
	journal = {Quarterly Journal of Speech},
	author = {Charland, Maurice},
	year = {1987},
	note = {Publisher: Taylor \& Francis Ltd},
	keywords = {Canada, Québec (Province), Rhetoric \& politics, Sovereignty},
	pages = {133},
}

@article{diebold2012,
	title = {A personal perspective on the origin(s) and development of'big data': {The} phenomenon, the term, and the discipline, second version},
	shorttitle = {A personal perspective on the origin (s) and development of'big data'},
	doi = {https://dx.doi.org/10.2139/ssrn.2202843},
	journal = {PIER Working Paper No. 13-003},
	author = {Diebold, Francis X.},
	year = {2012},
	note = {Publisher: PIER Working Paper},
}

@article{corbettdurfee2004,
	title = {Testing public (un) certainty of science: {Media} representations of global warming},
	volume = {26},
	shorttitle = {Testing public (un) certainty of science},
	number = {2},
	journal = {Science Communication},
	author = {Corbett, Julia B. and Durfee, Jessica L.},
	year = {2004},
	pages = {129--151},
}

@article{boydcrawford2012,
	title = {Critical questions for big data},
	volume = {15},
	issn = {1369-118X},
	url = {https://doi.org/10.1080/1369118X.2012.678878},
	doi = {10.1080/1369118X.2012.678878},
	abstract = {The era of Big Data has begun. Computer scientists, physicists, economists, mathematicians, political scientists, bio-informaticists, sociologists, and other scholars are clamoring for access to the massive quantities of information produced by and about people, things, and their interactions. Diverse groups argue about the potential benefits and costs of analyzing genetic sequences, social media interactions, health records, phone logs, government records, and other digital traces left by people. Significant questions emerge. Will large-scale search data help us create better tools, services, and public goods? Or will it usher in a new wave of privacy incursions and invasive marketing? Will data analytics help us understand online communities and political movements? Or will it be used to track protesters and suppress speech? Will it transform how we study human communication and culture, or narrow the palette of research options and alter what ‘research’ means? Given the rise of Big Data as a socio-technical phenomenon, we argue that it is necessary to critically interrogate its assumptions and biases. In this article, we offer six provocations to spark conversations about the issues of Big Data: a cultural, technological, and scholarly phenomenon that rests on the interplay of technology, analysis, and mythology that provokes extensive utopian and dystopian rhetoric.},
	number = {5},
	urldate = {2020-07-25},
	journal = {Information, Communication \& Society},
	author = {boyd, danah and Crawford, Kate},
	year = {2012},
	note = {Publisher: Routledge
\_eprint: https://doi.org/10.1080/1369118X.2012.678878},
	keywords = {Big Data, Twitter, analytics, communication studies, epistemology, ethics, philosophy of science, social media, social network sites},
	pages = {662--679},
}

@article{bylerboe2020,
	chapter = {World news},
	title = {Tech-enabled 'terror capitalism' is spreading worldwide. {The} surveillance regimes must be stopped},
	issn = {0261-3077},
	url = {https://www.theguardian.com/world/2020/jul/24/surveillance-tech-facial-recognition-terror-capitalism},
	abstract = {Terror capitalism uses tools such as facial recognition to extract profits from marginalized people. Big tech and governments are collaborating},
	language = {en-GB},
	urldate = {2020-07-24},
	journal = {The Guardian},
	author = {Byler, Darren and Boe, Carolina Sanchez},
	year = {2020},
	keywords = {Facial recognition, Surveillance, Technology, US news},
}

@book{bod2013a,
	title = {A new history of the humanities: {The} search for principles and patterns from antiquity to the present},
	isbn = {978-0-19-966521-1},
	shorttitle = {A new history of the humanities},
	abstract = {Many histories of science have been written, but A New History of the Humanities offers the first overarching history of the humanities from Antiquity to the present. There are already historical studies of musicology, logic, art history, linguistics, and historiography, but this volume gathers these, and many other humanities disciplines, into a single coherent account. Its central theme is the way in which scholars throughout the ages and in virtually all civilizations have sought to identify patterns in texts, art, music, languages, literature, and the past. What rules can we apply if we wish to determine whether a tale about the past is trustworthy? By what criteria are we to distinguish consonant from dissonant musical intervals? What rules jointly describe all possible grammatical sentences in a language? How can modern digital methods enhance pattern-seeking in the humanities? Rens Bod contends that the hallowed opposition between the sciences (mathematical, experimental, dominated by universal laws) and the humanities (allegedly concerned with unique events and hermeneutic methods) is a mistake born of a myopic failure to appreciate the pattern-seeking that lies at the heart of this inquiry. A New History of the Humanities amounts to a persuasive plea to give Panini, Valla, Bopp, and countless other often overlooked intellectual giants their rightful place next to the likes of Galileo, Newton, and Einstein.},
	language = {en},
	publisher = {Oxford University Press},
	author = {Bod, Rens},
	year = {2013},
	keywords = {Education / History, History / General, History / Modern / General, History / World},
}

@book{bod1998,
	address = {Stanford, CA},
	title = {Beyond grammar: {An} experience-based theory of language},
	shorttitle = {Beyond grammar},
	publisher = {CSLI Publications},
	author = {Bod, Rens},
	year = {1998},
	note = {Publisher: CSLI},
}

@article{bod2018,
	title = {Has there ever been a divide? {A} longue durée perspective},
	volume = {3},
	issn = {2379-3163},
	shorttitle = {Has there ever been a divide?},
	url = {https://www.journals.uchicago.edu/doi/abs/10.1086/696299},
	doi = {10.1086/696299},
	abstract = {This essay investigates the origins of the divide between what we nowadays refer to as the “sciences” and the “humanities.” It argues that from the third century BCE onward, there have been two opposing scholarly practices: searching for patterns versus understanding the unique. A longue durée analysis suggests that this opposition does not originate from a divide between the sciences and the humanities but from two opposing approaches in the humanities. Both approaches still prevail today.},
	number = {1},
	urldate = {2020-07-23},
	journal = {History of Humanities},
	author = {Bod, Rens},
	year = {2018},
	note = {Publisher: The University of Chicago Press},
	pages = {15--25},
}

@misc{bragin2019,
	title = {Observability with the elastic stack},
	url = {https://www.elastic.co/blog/observability-with-the-elastic-stack},
	language = {en-us},
	urldate = {2020-07-22},
	journal = {Elastic Blog},
	author = {Bragin, Tanya},
	year = {2019},
	note = {Library Catalog: www.elastic.co},
}

@article{boellstorff2013,
	title = {Making big data, in theory},
	volume = {18},
	issn = {13960466},
	url = {https://scholar-google-com.ezproxy.lib.ndsu.nodak.edu/scholar_lookup?hl=en&publication_year=2013&issue=10&author=Tom+Boellstorff&title=Making+Big+Data%2C+in+Theory},
	doi = {10.5210/fm.v18i10.4869},
	number = {10},
	urldate = {2020-07-17},
	journal = {First Monday},
	author = {Boellstorff, Tom},
	year = {2013},
	pages = {1--17},
}

@article{partington2010,
	title = {Modern diachronic corpus-assisted discourse studies ({MD}-{CADS}) on {UK} newspapers: {An} overview of the project},
	volume = {5},
	issn = {17495032},
	shorttitle = {Modern diachronic corpus-assisted discourse studies (md-cads) on uk newspapers},
	url = {https://ezproxy.lib.ndsu.nodak.edu/login?url=https://search.ebscohost.com/login.aspx?direct=true&db=ufh&AN=55983721&site=ehost-live&scope=site},
	doi = {10.3366/cor.2010.0101},
	abstract = {This edition of Corpora contains one of the first ever collections of papers pertaining to the nascent discipline of Modern Diachronic Corpus-Assisted Discourse Studies (MD-CADS). This discipline is characterised by the novelty both of its methodology and the topics it is, consequently, in a position to treat. It employs relatively large corpora of a parallel structure and content from different moments of contemporary time (in this case the SiBol corpora, see below) in order to track changes in modern language usage but also social, cultural and political changes as reflected in language. In this overview, I will attempt to give an idea of what both corpus-assisted discourse studies (CADS) and MD-CADS involve, to provide some information about the newspaper corpora we employ, and to outline methodologies commonly followed in this area, including those employed by the other contributors to this issue. I will also present two sets of practical analyses. The first is inductive and bottom-up, derived from a close analysis of the comparative keywords generated by comparing the lists of items from the two parallel corpora from different time periods; the aim is to uncover changes over time both in language and in what social, political and cultural issues were considered worthy of attention. The second is more intuitive and hypothesis-driven; the hypothesis is that an examination of a certain term, namely moral panic, can shed some light on which issues writers thought did not merit all the attention they were receiving. I will conclude with brief sketches of the other papers in this issue, and reflections on the relevance of MD-CADS in both language research and teaching.},
	number = {2},
	urldate = {2020-01-09},
	journal = {Corpora},
	author = {Partington, Alan},
	month = nov,
	year = {2010},
	keywords = {Corpora (Linguistics), Discourse, Language \& languages, Moral panics, Panic, Teaching},
	pages = {83--108},
}

@incollection{watzlawick_tentative_1967,
	address = {New York, NY},
	title = {Some tentative axioms of communication},
	booktitle = {Pragmatics of {Human} {Communication}: {A} {Study} of {Interactional} {Patterns}, {Pathologies} and {Paradoxes}},
	publisher = {W. W. Nortion \& Company},
	author = {Watzlawick, Paul and Beavin, Janet Helmick and Jackson, Don D.},
	year = {1967},
	pages = {48--71},
}

@incollection{blom_mode_2004,
	title = {The mode of information and postmodernity},
	isbn = {978-1-00-008276-0},
	language = {en},
	booktitle = {The {Information} {Society} {Reader}},
	publisher = {Routledge},
	author = {Poster, Mark},
	editor = {Blom, Raimo and Karvonen, Erkki and Melin, Harri and Nordenstreng, Kaarle and Puoskari, Ensio and Webster, Frank and Webster, Professor Frank},
	year = {2004},
	keywords = {Social Science / Sociology / General},
	pages = {398--410},
}

@book{pomerantz_metadata_2015,
	title = {Metadata},
	isbn = {978-0-262-33120-3},
	abstract = {Everything we need to know about metadata, the usually invisible infrastructure for information with which we interact every day. When “metadata” became breaking news, appearing in stories about surveillance by the National Security Agency, many members of the public encountered this once-obscure term from information science for the first time. Should people be reassured that the NSA was “only” collecting metadata about phone calls—information about the caller, the recipient, the time, the duration, the location—and not recordings of the conversations themselves? Or does phone call metadata reveal more than it seems? In this book, Jeffrey Pomerantz offers an accessible and concise introduction to metadata.In the era of ubiquitous computing, metadata has become infrastructural, like the electrical grid or the highway system. We interact with it or generate it every day. It is not, Pomerantz tell us, just “data about data.” It is a means by which the complexity of an object is represented in a simpler form. For example, the title, the author, and the cover art are metadata about a book. When metadata does its job well, it fades into the background; everyone (except perhaps the NSA) takes it for granted.Pomerantz explains what metadata is, and why it exists. He distinguishes among different types of metadata—descriptive, administrative, structural, preservation, and use—and examines different users and uses of each type. He discusses the technologies that make modern metadata possible, and he speculates about metadata's future. By the end of the book, readers will see metadata everywhere. Because, Pomerantz warns us, it's metadata's world, and we are just living in it.},
	language = {en},
	publisher = {MIT Press},
	author = {Pomerantz, Jeffrey},
	year = {2015},
	keywords = {Business \& Economics / Information Management, Computers / Data Modeling \& Design},
}

@article{luhmann_what_1992,
	title = {What is communication?},
	volume = {2},
	number = {3},
	journal = {Communication Theory},
	author = {Luhmann, Niklas},
	year = {1992},
	note = {Publisher: Wiley Online Library},
	pages = {251--259},
}

@incollection{koteyko2015,
	title = {Corpus-assisted analysis of {Internet}-based discourses: {From} patterns to rhetoric},
	shorttitle = {Corpus-assisted analysis of {Internet}-based discourses},
	booktitle = {Rhetoric and the {Digital} {Humanities}},
	publisher = {University of Chicago Press},
	author = {Koteyko, Nelya},
	editor = {Ridolfo, Jim and Hart-Davidson, William},
	year = {2015},
	pages = {184--198},
}

@incollection{west_redeveloping_2001,
	title = {Redeveloping {DICTION}: {Theoretical} considerations},
	isbn = {978-1-56750-503-0},
	language = {en},
	booktitle = {Theory, method, and practice in computer content analysis},
	publisher = {Greenwood Publishing Group},
	author = {Hart, Roderick P.},
	editor = {West, Mark D.},
	year = {2001},
	keywords = {Computers / Information Theory, Social Science / Research},
	pages = {43--60},
}

@book{flyverbom_digital_2019,
	title = {The digital prism},
	isbn = {978-1-107-13081-4},
	abstract = {We live in times of transparency. Digital technologies expose everything we do, like, and search for, and it is difficult to remain private and out of sight. Meanwhile, many people are concerned about the unchecked powers of tech giants and the hidden operations of big data, artificial intelligence and algorithms and call for more openness and insight. How do we - as individuals, companies and societies - deal with these technological and social transformations? Seen through the prism of digital technologies and data, our lives take new shapes and we are forced to manage our visibilities carefully. This book challenges common ways of thinking about transparency, and argues that the management of visibilities is a crucial, but overlooked force that influences how people live, how organizations work, and how societies and politics operate in a digital, datafied world.},
	language = {en},
	publisher = {Cambridge University Press},
	author = {Flyverbom, Mikkel},
	year = {2019},
	keywords = {Business \& Economics / General, Business \& Economics / Industries / Media \& Communications, Business \& Economics / Organizational Behavior, Computers / Information Technology, Social Science / Sociology / General},
}

@article{saltelli_five_2020,
	title = {Five ways to ensure that models serve society: a manifesto},
	volume = {582},
	copyright = {2020 Nature},
	shorttitle = {Five ways to ensure that models serve society},
	url = {https://www.nature.com/articles/d41586-020-01812-9},
	doi = {10.1038/d41586-020-01812-9},
	abstract = {Pandemic politics highlight how predictions need to be transparent and humble to invite insight, not blame.},
	language = {en},
	number = {7813},
	urldate = {2020-07-27},
	journal = {Nature},
	author = {Saltelli, Andrea and Bammer, Gabriele and Bruno, Isabelle and Charters, Erica and Fiore, Monica Di and Didier, Emmanuel and Espeland, Wendy Nelson and Kay, John and Piano, Samuele Lo and Mayo, Deborah and Jr, Roger Pielke and Portaluri, Tommaso and Porter, Theodore M. and Puy, Arnald and Rafols, Ismael and Ravetz, Jerome R. and Reinert, Erik and Sarewitz, Daniel and Stark, Philip B. and Stirling, Andrew and Sluijs, Jeroen van der and Vineis, Paolo},
	year = {2020},
	pages = {482--484},
}

@article{greene_cognitive_1984,
	title = {A cognitive approach to human communication: {An} action assembly theory},
	volume = {51},
	journal = {Communication Monographs},
	author = {Greene, John O.},
	year = {1984},
	pages = {289--306},
}

@article{koteykoetal2013,
	title = {Climate change and ‘climategate’ in online reader comments: a mixed methods study},
	volume = {179},
	issn = {0016-7398},
	shorttitle = {Climate change and ‘climategate’ in online reader comments},
	url = {https://rgs-ibg.onlinelibrary.wiley.com/doi/full/10.1111/j.1475-4959.2012.00479.x},
	doi = {10.1111/j.1475-4959.2012.00479.x},
	abstract = {Climate change has rarely been out of the public spotlight in the first decade of this century. The high-profile international meetings and controversies such as ?climategate? have highlighted the fact that it is as much a political issue as it is a scientific one, while also drawing our attention to the role of social media in reflecting, promoting or resisting such politicisation. In this article, we propose a framework for analysing one type of social media venue that so far has received little attention from social scientists ? online reader comments. Like media reporting on climate change, reader comments on this reporting contribute to the diverse, complex and contested discourses on climate change, and can reveal the meanings and discursive resources brought to the ongoing debate by laypeople rather than political elites. The proposed framework draws on research in computer-mediated communication, corpus linguistics and discourse analysis and takes into account both the content of such ?lay talk? and its linguistic characteristics within the specific parameters of the web-based context. Using word frequencies, qualitative study of co-text and user ratings, we analyse a large volume of comments published on the UK tabloid newspaper website at two different points in time ? before and after the East Anglia controversy. The results reveal how stereotypes of science and politics are appropriated in this type of discourse, how readers? constructions of climate science have changed after ?climategate?, and how climate-sceptic arguments are adopted and contested in computer-mediated peer-to-peer interaction.},
	number = {1},
	urldate = {2020-01-09},
	journal = {The Geographical Journal},
	author = {Koteyko, Nelya and Jaspal, Rusi and Nerlich, Brigitte},
	year = {2013},
	keywords = {climate scepticism, corpus linguistics, discourse analysis, online reader comments, ‘climategate’},
	pages = {74--86},
}

@article{whimster_pure_2018,
	title = {Pure relationality as a sociological theory of communication},
	volume = {3},
	issn = {2297-7775},
	url = {https://www.frontiersin.org/articles/10.3389/fsoc.2018.00001/full},
	doi = {10.3389/fsoc.2018.00001},
	abstract = {In order to explain the success of populist politicians use of social media, we need to subtract the social from relationality and separate social relationships from network theory applications. A pure theory of relationality is suggested by Werner Heisenberg's breakthrough in quantum mechanics. It is argued that sociology, to its detriment, has failed to incorporate a theory of communication, one adequate to the explosion of social media and the recent rise of populist politics, here instanced by Donald Trump. Realizing the underlying importance of communication technology in all social relationships, and treating these two aspects in a complementary fashion, is the purpose of this essay in sociological theory.},
	language = {English},
	urldate = {2020-07-06},
	journal = {Frontiers in Sociology},
	author = {Whimster, Sam},
	year = {2018},
	note = {Publisher: Frontiers},
	keywords = {Communication, Donald Trump, network theory, populist politics, relationality},
}

@techreport{nist_big_data_public_working_group_definitions_and_taxonomies_subgroup_nist_2015,
	title = {Nist big data interoperability framework: {Volume} 1, definitions},
	shorttitle = {Nist big data interoperability framework},
	url = {https://nvlpubs.nist.gov/nistpubs/SpecialPublications/NIST.SP.1500-1.pdf},
	abstract = {Big Data is a term used to describe the large amount of data in the networked, digitized, sensor-laden, information-driven world. While opportunities exist with Big Data, the data can overwhelm traditional technical approaches and the growth of data is outpacing scientific and technological advances in data analytics. To advance progress in Big Data, the NIST Big Data Public Working Group (NBD-PWG) is working to develop consensus on important, fundamental concepts related to Big Data. The results are reported in the NIST Big Data Interoperability Framework series of volumes. This volume, Volume 1, contains a definition of Big Data and related terms necessary to lay the groundwork for discussions surrounding Big Data.},
	language = {en},
	number = {NIST SP 1500-1},
	urldate = {2020-06-29},
	institution = {National Institute of Standards and Technology},
	author = {{NIST Big Data Public Working Group Definitions and Taxonomies Subgroup}},
	month = oct,
	year = {2015},
	doi = {10.6028/NIST.SP.1500-1},
	pages = {NIST SP 1500--1},
}

@misc{new_relic_age_2020,
	title = {The age of observability},
	url = {https://newrelic.com/resources/ebooks/what-is-observability},
	abstract = {Why the Future Is Open, Connected, and Programmable},
	language = {en},
	urldate = {2020-07-22},
	journal = {New Relic},
	author = {{New Relic}},
	year = {2020},
	note = {Library Catalog: newrelic.com},
}

@misc{nanakul_storytelling_2015,
	title = {Storytelling with data: {Our} brains crave structure + love oddballs},
	shorttitle = {Storytelling with data},
	url = {https://www.tableau.com/about/blog/2015/11/channel-your-inner-oddball-when-storytelling-data-46032},
	language = {en},
	urldate = {2020-07-21},
	journal = {Tableau Software},
	author = {Nanakul, Ravi},
	year = {2015},
	note = {Library Catalog: www.tableau.com},
}

@misc{microsoft_big_2019,
	title = {Big data architecture style - {Azure} application architecture guide},
	url = {https://docs.microsoft.com/en-us/azure/architecture/guide/architecture-styles/big-data},
	abstract = {Describes benefits, challenges, and best practices for Big Data architectures on Azure.},
	language = {en-us},
	urldate = {2020-07-23},
	author = {{Microsoft}},
	year = {2019},
	note = {Library Catalog: docs.microsoft.com},
}

@article{manning_review_2002,
	title = {Review: {Rens} {Bod}, {Beyond} grammar: an experience-based theory of language},
	volume = {38},
	issn = {1469-7742, 0022-2267},
	shorttitle = {Rens {Bod}, {Beyond} grammar},
	url = {https://www.cambridge.org/core/journals/journal-of-linguistics/article/rens-bod-beyond-grammar-an-experiencebased-theory-of-language-stanford-ca-csli-publications-1998-pp-xiii168/8412E7041A3ED11776D5F1865D3B4009},
	doi = {10.1017/S0022226702211639},
	abstract = {//static.cambridge.org/content/id/urn\%3Acambridge.org\%3Aid\%3Aarticle\%3AS0022226702211639/resource/name/firstPage-S0022226702001639a.jpg},
	language = {en},
	number = {2},
	urldate = {2020-07-23},
	journal = {Journal of Linguistics},
	author = {Manning, Christopher D.},
	year = {2002},
	note = {Publisher: Cambridge University Press},
	pages = {441--462},
}

@article{lewis_big_2015,
	title = {Big data and journalism},
	volume = {3},
	issn = {2167-0811},
	url = {https://doi.org/10.1080/21670811.2014.976418},
	doi = {10.1080/21670811.2014.976418},
	abstract = {Big data is a social, cultural, and technological phenomenon—a complex amalgamation of digital data abundance, emerging analytic techniques, mythology about data-driven insights, and growing critique about the overall consequences of big-data practices for democracy and society. While media and communication scholars have begun to examine and theorize about big data in the context of media and public life broadly, what are the particular implications for journalism? This article introduces and applies four conceptual lenses—epistemology, expertise, economics, and ethics—to explore both contemporary and potential applications of big data for the professional logic and industrial production of journalism. These distinct yet inter-related conceptual approaches reveal how journalists and news media organizations are seeking to make sense of, act upon, and derive value from big data during a time of exploration in algorithms, computation, and quantification. In all, the developments of big data potentially have great meaning for journalism’s ways of knowing (epistemology) and doing (expertise), as well as its negotiation of value (economics) and values (ethics). Ultimately, this article outlines future directions for journalism studies research in the context of big data.},
	number = {3},
	urldate = {2020-07-17},
	journal = {Digital Journalism},
	author = {Lewis, Seth C. and Westlund, Oscar},
	year = {2015},
	note = {Publisher: Routledge
\_eprint: https://doi.org/10.1080/21670811.2014.976418},
	keywords = {algorithms, big data, computational journalism, epistemology, expertise, journalism ethics, media economics, media innovation, technology},
	pages = {447--466},
}

@misc{kobielus_surprise_2016,
	title = {Surprise in the narrative flow of data science},
	url = {https://www.linkedin.com/pulse/surprise-narrative-flow-data-science-james-kobielus},
	abstract = {Data science is the search for surprising insights in empirical data sets of any complexity. By “surprising,” I’m referring to any discovery that the data scientist might present as the unexpected, non-obvious, validating outcome of their statistical quest to find meaning in the data.},
	language = {en},
	urldate = {2020-07-21},
	author = {Kobielus, James},
	year = {2016},
	note = {Library Catalog: www.linkedin.com},
}

@article{iliadis_algorithms_2018,
	title = {Algorithms, ontology, and social progress},
	volume = {14},
	issn = {1742-7665},
	url = {https://doi.org/10.1177/1742766518776688},
	doi = {10.1177/1742766518776688},
	abstract = {Recently, media and communication researchers have shown an increasing interest in critical data studies and ways to utilize data for social progress. In this commentary, I highlight several useful contributions in the International Panel on Social Progress (IPSP) report toward identifying key data justice issues, before suggesting extra focus on algorithmic discrimination and implicit bias. Following my assessment of the IPSP’s report, I emphasize the importance of two emerging media and communication areas – applied ontology and semantic technology – that impact internet users daily, yet receive limited attention from critical data researchers. I illustrate two examples to show how applied ontologies and semantic technologies impact social processes by engaging in the hierarchization of social relations and entities, a practice that will become more common as the Internet changes states towards a ‘smarter’ version of itself.},
	language = {en},
	number = {2},
	urldate = {2020-07-25},
	journal = {Global Media and Communication},
	author = {Iliadis, Andrew},
	year = {2018},
	note = {Publisher: SAGE Publications},
	pages = {219--230},
}

@misc{kana_bayesian_2020,
	title = {Bayesian nightmare. {Solved}!},
	url = {https://towardsdatascience.com/bayesian-nightmare-how-to-start-loving-bayes-1622741fa960},
	abstract = {Gentle introduction to Bayesian data analysis by examples and code in Python PyMC3.},
	language = {en},
	urldate = {2020-07-27},
	journal = {Medium},
	author = {Kana, Michel},
	year = {2020},
	note = {Library Catalog: towardsdatascience.com},
}

@incollection{drucker_humanistic_2012,
	address = {Minneapolis},
	title = {Humanistic theory and digital scholarship},
	booktitle = {Debates in the {Digital} {Humanities}},
	publisher = {University of Minnesota Press},
	author = {Drucker, Johanna},
	editor = {Gold, Matthew K.},
	year = {2012},
	pages = {85--95},
}

@article{mays_writing_2017,
	title = {Writing complexity, one stability at a time: {Teaching} writing as a complex system},
	volume = {68},
	shorttitle = {Writing complexity, one stability at a time},
	number = {3},
	journal = {College Composition and Communication},
	author = {Mays, Chris},
	year = {2017},
	note = {Publisher: National Council of Teachers of English},
	pages = {559},
}

@article{floridi2012,
	title = {Big data and their epistemological challenge},
	volume = {25},
	number = {4},
	journal = {Philosophy \& Technology},
	author = {Floridi, Luciano},
	year = {2012},
	note = {Publisher: Springer},
	pages = {435--437},
}

@article{wilsonetal2020,
	title = {From incremental to transformative adaptation in individual responses to climate-exacerbated hazards},
	copyright = {2020 Springer Nature Limited},
	issn = {1758-6798},
	url = {https://www.nature.com/articles/s41558-020-0691-6},
	doi = {10.1038/s41558-020-0691-6},
	abstract = {Individual responses to climate hazards can contribute to long-term societal resilience. This Review finds that the literature emphasizes intrapersonal cognitive and affective drivers of adaptation behaviour rather than the interpersonal social factors that promote coordinated cooperative action.},
	language = {en},
	urldate = {2020-02-18},
	journal = {Nature Climate Change},
	author = {Wilson, Robyn S. and Herziger, Atar and Hamilton, Matthew and Brooks, Jeremy S.},
	month = feb,
	year = {2020},
	pages = {1--9},
}

@article{walker_body_1994,
	title = {The {Body} of {Persuasion}: {A} {Theory} of the {Enthymeme}},
	volume = {56},
	issn = {0010-0994},
	shorttitle = {The {Body} of {Persuasion}},
	url = {https://www.jstor.org/stable/378216},
	doi = {10.2307/378216},
	number = {1},
	urldate = {2020-01-27},
	journal = {College English},
	author = {Walker, Jeffrey},
	year = {1994},
	pages = {46--65},
}

@article{lahn_history_2019,
	title = {A history of the global carbon budget},
	volume = {n/a},
	copyright = {© 2020 The Author. WIREs Climate Change published by Wiley Periodicals, Inc.},
	issn = {1757-7799},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/wcc.636},
	doi = {10.1002/wcc.636},
	abstract = {The idea of a global “carbon budget”—the cumulative amount of “allowable” carbon emissions to meet a global temperature target—has become established as a central concept in climate science and policy. As a concept explicitly aimed at mediating between scientific knowledge and policymaking, the carbon budget has always been actively positioned in relation to ongoing policy debates, but the specific forms this concept has taken have varied. This article reviews key contributions to the carbon budget literature from the 1980s until today, in order to identify how scientists have positioned the concept between the worlds of science and policy. Three main shifts are identified in how the policy relevance of the carbon budget is envisaged in the scientific literature. The shifts can be related in part to developments in climate science, and in part to changes in international climate policy. The history of the carbon budget thus illustrates how science and policy interacts to shape dominant understandings of how climate change can be known and governed. This article is categorized under: Climate, History, Society, Culture {\textgreater} Ideas and Knowledge},
	language = {en},
	number = {n/a},
	urldate = {2020-01-23},
	journal = {WIREs Climate Change},
	author = {Lahn, Bård},
	year = {2019},
	keywords = {boundary work, carbon budgets, climate policy targets, cumulative emissions, science/policy interface},
	pages = {e636},
}

@incollection{flottum2019,
	title = {A cross-disciplinary perspective on climate change discourse},
	isbn = {978-3-7329-0420-4},
	language = {en},
	booktitle = {New {Challenges} for {Research} on {Language} for {Special} {Purposes}},
	publisher = {Frank \& Timme GmbH},
	author = {Fløttum, Kjersti},
	year = {2019},
	pages = {21--37},
}

@article{opel_architecture_2013,
	title = {The architecture of provider-parent vaccine discussions at health supervision visits},
	volume = {132},
	copyright = {Copyright © 2013 by the American Academy of Pediatrics},
	issn = {0031-4005, 1098-4275},
	url = {https://pediatrics.aappublications.org/content/132/6/1037},
	doi = {10.1542/peds.2013-2037},
	abstract = {OBJECTIVE: To characterize provider-parent vaccine communication and determine the influence of specific provider communication practices on parent resistance to vaccine recommendations.
METHODS: We conducted a cross-sectional observational study in which we videotaped provider-parent vaccine discussions during health supervision visits. Parents of children aged 1 to 19 months old were screened by using the Parent Attitudes about Childhood Vaccines survey. We oversampled vaccine-hesitant parents (VHPs), defined as a score ≥50. We developed a coding scheme of 15 communication practices and applied it to all visits. We used multivariate logistic regression to explore the association between provider communication practices and parent resistance to vaccines, controlling for parental hesitancy status and demographic and visit characteristics.
RESULTS: We analyzed 111 vaccine discussions involving 16 providers from 9 practices; 50\% included VHPs. Most providers (74\%) initiated vaccine recommendations with presumptive (eg, “Well, we have to do some shots”) rather than participatory (eg, “What do you want to do about shots?”) formats. Among parents who voiced resistance to provider initiation (41\%), significantly more were VHPs than non-VHPs. Parents had significantly higher odds of resisting vaccine recommendations if the provider used a participatory rather than a presumptive initiation format (adjusted odds ratio: 17.5; 95\% confidence interval: 1.2–253.5). When parents resisted, 50\% of providers pursued their original recommendations (eg, “He really needs these shots”), and 47\% of initially resistant parents subsequently accepted recommendations when they did.
CONCLUSIONS: How providers initiate and pursue vaccine recommendations is associated with parental vaccine acceptance.},
	language = {en},
	number = {6},
	urldate = {2020-01-17},
	journal = {Pediatrics},
	author = {Opel, Douglas J. and Heritage, John and Taylor, James A. and Mangione-Smith, Rita and Salas, Halle Showalter and DeVere, Victoria and Zhou, Chuan and Robinson, Jeffrey D.},
	year = {2013},
	pmid = {24190677},
	keywords = {health communication, immunization, preventive health services},
	pages = {1037--1046},
}

@article{herrera_symposium_2004,
	title = {Symposium: {Discourse} and {Content} {Analysis}},
	language = {en},
	author = {Herrera, Yoshiko M},
	year = {2004},
	pages = {25},
}

@article{flottumetal2014,
	title = {Representations of the future in {English} language blogs on climate change},
	volume = {29},
	issn = {0959-3780},
	url = {http://www.sciencedirect.com/science/article/pii/S0959378014001721},
	doi = {10.1016/j.gloenvcha.2014.10.005},
	abstract = {This paper investigates how the notion of future is represented in a large corpus of English-language blogs related to climate change, with an overarching interest in exploring to what extent the perspectives of gloom-and-doom versus more positive perspectives of a sustainable society are represented. We address the following questions: (1) How are representations of the future expressed linguistically in public debates related to climate change? (2) What meanings do the representations convey? Our principal contribution is a set of nine meaning categories that characterize different representations of the future: the categories were derived by following a corpus-assisted discourse analysis approach. Within these categories, the large presence of characterisations related to sustainability, as well as frequent positive value-laden characterisations, are noteworthy. Representations reflect various perspectives of a future for humanity, for nature, and for countries as well as for economies. Further, we have found that when climate change is viewed as a threat, it is in relation to nature, humans and security, while it is seen as an opportunity for growth in business and industry. The results provide knowledge on how people conceive the possible impacts of global climate and environmental change within two broad perspectives of a “gloom-and-doom” versus a “bright” future. This may contribute to an improved basis for political decision making on measures in order to avoid dangerous consequences as well as to encourage engagement in the shift toward a low-carbon future.},
	language = {en},
	urldate = {2020-01-10},
	journal = {Global Environmental Change},
	author = {Fløttum, Kjersti and Gjesdal, Anje Müller and Gjerstad, Øyvind and Koteyko, Nelya and Salway, Andrew},
	month = nov,
	year = {2014},
	keywords = {Blogosphere, Corpus-assisted discourse analysis, Future representations, Online discourses},
	pages = {213--222},
}

@article{zhengetal2020,
	title = {"{Love} is as complex as math": {Metaphor} generation system for social chatbot},
	shorttitle = {"{Love} is as complex as math"},
	url = {http://arxiv.org/abs/2001.00733},
	abstract = {As the wide adoption of intelligent chatbot in human daily life, user demands for such systems evolve from basic task-solving conversations to more casual and friend-like communication. To meet the user needs and build emotional bond with users, it is essential for social chatbots to incorporate more human-like and advanced linguistic features. In this paper, we investigate the usage of a commonly used rhetorical device by human -- metaphor for social chatbot. Our work first designs a metaphor generation framework, which generates topic-aware and novel figurative sentences. By embedding the framework into a chatbot system, we then enables the chatbot to communicate with users using figurative language. Human annotators validate the novelty and properness of the generated metaphors. More importantly, we evaluate the effects of employing metaphors in human-chatbot conversations. Experiments indicate that our system effectively arouses user interests in communicating with our chatbot, resulting in significantly longer human-chatbot conversations.},
	urldate = {2020-01-08},
	journal = {arXiv:2001.00733 [cs]},
	author = {Zheng, Danning and Song, Ruihua and Hu, Tianran and Fu, Hao and Zhou, Jin},
	year = {2020},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
}

@misc{majdik2019a,
	edition = {1st},
	title = {When expertises clash: ({Topic}) modeling stasis about complex issues across large discursive corpora},
	copyright = {All rights reserved},
	language = {en},
	urldate = {2020-01-08},
	journal = {The Routledge Handbook of Language and Science},
	publisher = {Routledge},
	author = {Majdik, Zoltan P.},
	year = {2019},
}

@article{grahamherndl2011,
	title = {Talking off-label: {The} role of stasis in transforming the discursive formation of pain science},
	volume = {41},
	issn = {0277-3945, 1930-322X},
	shorttitle = {Talking off-label},
	url = {http://www.tandfonline.com/doi/abs/10.1080/02773945.2011.553764},
	doi = {10.1080/02773945.2011.553764},
	language = {en},
	number = {2},
	urldate = {2020-01-04},
	journal = {Rhetoric Society Quarterly},
	author = {Graham, S. Scott and Herndl, Carl G.},
	year = {2011},
	pages = {145--167},
}

@article{lametal2019,
	title = {Stakeholder concerns of air pollution in {Hong} {Kong} and policy implications: {A} big-data computational text analysis approach},
	volume = {101},
	issn = {1462-9011},
	shorttitle = {Stakeholder concerns of air pollution in {Hong} {Kong} and policy implications},
	url = {http://www.sciencedirect.com/science/article/pii/S1462901119300292},
	doi = {10.1016/j.envsci.2019.07.007},
	abstract = {Stakeholder engagement is critical to the successful formulation and implementation of environmental policies. Text analysis can serve as an important means to decipher stakeholder (dis)agreements. Traditionally, researchers analyze texts using qualitative text analysis. Relying only on qualitative text analysis can no longer be sufficient to handle very large amounts of textual data. Now computational methods can be applied to help extract opinions in electronic texts. Our paper adopts a big data computational text analysis approach (keyword analysis, keyword co-occurrence, thematic analysis), based on a corpus of 2.4 million words, to compare concerns towards air pollution among three stakeholder groups (i.e. the government (GOV), the environmental groups (NGO) and the news media (MEDIA)) in Hong Kong, between 2002 and 2012, a period when air pollution was subject to rigorous policy debates and discussions. Our analysis shows the somewhat different concerns of the stakeholders. The stakeholders focus heavily on emissions and end-of-pipe pollution control. Though the advocation of sustainability since 1990s, the government-led command-and-control approach still dictates the discourse. Sustainability is featured more intensively by the Hong Kong Special Administrative Region (HKSAR) Government. Transboundary pollution (e.g. from Guangdong, China) is not a major concern for all stakeholder groups. Public health is a greater concern in MEDIA, as compared to the other two stakeholder groups. Future air pollution policy-making may direct more of its attention to the pressing concerns over the negative impacts of air pollution on health and its associated costs, with health experts getting more closely involved in the regulatory decision-makings. More information should be given to vulnerable groups, such as young children or workers in polluted environments. To better relate differential health risks of pollution in everyday life, both local and international governments should consider developing more personalized air pollution monitoring and health management systems for their citizens in future.},
	language = {en},
	urldate = {2020-01-03},
	journal = {Environmental Science \& Policy},
	author = {Lam, Jacqueline C. K. and Cheung, Lawrence Y. L. and Wang, Shanshan and Li, Victor O. K.},
	year = {2019},
	keywords = {Air pollution, Big data, Computational text analysis, Personalisation, Public health, Stakeholder concerns},
	pages = {374--382},
}

@article{toffnielsen2018,
	title = {“{I} just {Google} it”: {Folk} theories of distributed discovery},
	volume = {68},
	shorttitle = {“{I} just {Google} it”},
	number = {3},
	journal = {Journal of Communication},
	author = {Toff, Benjamin and Nielsen, Rasmus Kleis},
	year = {2018},
	pages = {636--657},
}

@article{koteykoetal2010,
	title = {From carbon markets to carbon morality: {Creative} compounds as framing devices in online discourses on climate change mitigation},
	volume = {32},
	shorttitle = {From carbon markets to carbon morality},
	number = {1},
	journal = {Science Communication},
	author = {Koteyko, Nelya and Thelwall, Mike and Nerlich, Brigitte},
	year = {2010},
	pages = {25--54},
}
